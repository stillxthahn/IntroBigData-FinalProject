{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92a57230",
   "metadata": {},
   "source": [
    "# 3.1. Classification with Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def07487",
   "metadata": {},
   "source": [
    "### Import libraries and load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a54f119c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS, LogisticRegressionWithSGD\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.mllib.linalg import Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "517c4fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"RDD-Based-Implementation\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd688b9",
   "metadata": {},
   "source": [
    "### 3.1.2. MLlib RDD-Based Implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b302a500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+\n",
      "|            features|Class|      scaledFeatures|\n",
      "+--------------------+-----+--------------------+\n",
      "|[1.38639697419213...|    0|[0.71005441038295...|\n",
      "|[-2.1434575316891...|    0|[-1.0977890908419...|\n",
      "|[-4.0668622711825...|    0|[-2.0828763664576...|\n",
      "|[-0.9456431509172...|    0|[-0.4843187791494...|\n",
      "|[-3.5900235269187...|    0|[-1.8386595514265...|\n",
      "|[-3.8405843371581...|    0|[-1.9669862945538...|\n",
      "|[-0.7353859070637...|    0|[-0.3766338331402...|\n",
      "|[-1.4000322465173...|    0|[-0.7170378252573...|\n",
      "|[-1.4539401037675...|    0|[-0.7446471698442...|\n",
      "|[0.91196330496498...|    0|[0.46706937396133...|\n",
      "|[-2.6686038604838...|    0|[-1.3667470255448...|\n",
      "|[1.29926838042254...|    0|[0.66543079721284...|\n",
      "|[-1.1892931244430...|    0|[-0.6091060814244...|\n",
      "|[-0.9282650755347...|    0|[-0.4754184574530...|\n",
      "|[1.15444484782558...|    0|[0.59125825503196...|\n",
      "|[1.2095749964979,...|    0|[0.61949360604508...|\n",
      "|[-0.4483096494488...|    0|[-0.2296054086484...|\n",
      "|[-0.4150216942969...|    0|[-0.2125567134996...|\n",
      "|[-0.3025206900136...|    0|[-0.1549384153131...|\n",
      "|[-1.0988332875806...|    0|[-0.5627763451928...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = spark.read.parquet(\"../../data/creditcard_preprocessed.parquet\")\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1d6aa490",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lxtha\\AppData\\Roaming\\Python\\Python310\\site-packages\\pyspark\\mllib\\classification.py:395: FutureWarning: Deprecated in 2.0.0. Use ml.classification.LogisticRegression or LogisticRegressionWithLBFGS.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9947194959849961\n",
      "Precision: 0.9981011234720676\n",
      "Recall: 0.9947194959849961\n",
      "F1 Score: 0.996156160582718\n"
     ]
    }
   ],
   "source": [
    "# Convert scaledFeatures to pyspark.mllib.linalg.Vector\n",
    "rdd_data = data.rdd.map(lambda row: LabeledPoint(row['Class'], Vectors.dense(row['scaledFeatures'].toArray())))\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_rdd, test_rdd = rdd_data.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Train the logistic regression model\n",
    "model = LogisticRegressionWithSGD.train(train_rdd, iterations=100)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions_and_labels = test_rdd.map(lambda lp: (float(model.predict(lp.features)), lp.label))\n",
    "\n",
    "# Compute evaluation metrics\n",
    "metrics = MulticlassMetrics(predictions_and_labels)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f\"Accuracy: {metrics.accuracy}\")\n",
    "print(f\"Precision: {metrics.weightedPrecision}\")\n",
    "print(f\"Recall: {metrics.weightedRecall}\")\n",
    "print(f\"F1 Score: {metrics.weightedFMeasure()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "92702f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
