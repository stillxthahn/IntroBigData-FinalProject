{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T13:43:07.407665Z",
     "iopub.status.busy": "2025-04-11T13:43:07.407333Z",
     "iopub.status.idle": "2025-04-11T13:43:15.380692Z",
     "shell.execute_reply": "2025-04-11T13:43:15.379387Z",
     "shell.execute_reply.started": "2025-04-11T13:43:07.407621Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import math\n",
    "import time\n",
    "\n",
    "# Create a SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"CreditCardFraud_LowLevel\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "We load the credit card fraud dataset into an RDD using low-level Spark operations:\n",
    "- Read the CSV file directly with `textFile`.\n",
    "- Filter out the header row to process only data rows.\n",
    "- Print the total number of records for verification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T13:43:15.382663Z",
     "iopub.status.busy": "2025-04-11T13:43:15.381967Z",
     "iopub.status.idle": "2025-04-11T13:43:20.377959Z",
     "shell.execute_reply": "2025-04-11T13:43:20.376889Z",
     "shell.execute_reply.started": "2025-04-11T13:43:15.382619Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of records: 284807\n"
     ]
    }
   ],
   "source": [
    "# Path to the credit card dataset in Kaggle\n",
    "credit_card_path = \"/kaggle/input/creditcardfraud/creditcard.csv\"\n",
    "\n",
    "# Load the CSV file as a text file and filter out the header\n",
    "lines_rdd = sc.textFile(credit_card_path)\n",
    "header = lines_rdd.first()\n",
    "data_rdd_raw = lines_rdd.filter(lambda line: line != header)\n",
    "\n",
    "# Quick count of the raw data\n",
    "print(f\"Total number of records: {data_rdd_raw.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Parsing and Initial Analysis\n",
    "We parse the raw text data into features and labels, and analyze the dataset:\n",
    "- Convert each line into a tuple of (features, label).\n",
    "- Cache the parsed RDD for efficiency.\n",
    "- Analyze class distribution to understand the dataset's imbalance (fraud vs. non-fraud).\n",
    "- Print the total valid records, number of features, class distribution, and a sample record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T13:43:20.379303Z",
     "iopub.status.busy": "2025-04-11T13:43:20.379009Z",
     "iopub.status.idle": "2025-04-11T13:43:27.681214Z",
     "shell.execute_reply": "2025-04-11T13:43:27.680187Z",
     "shell.execute_reply.started": "2025-04-11T13:43:20.379278Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total valid records: 284807\n",
      "Number of features: 30\n",
      "Class distribution: {0.0: 284315, 1.0: 492}\n",
      "Percentage of fraudulent transactions: 0.1727%\n",
      "\n",
      "Sample record (features, label):\n",
      "([0.0, -1.3598071336738, -0.0727811733098497, 2.53634673796914, 1.37815522427443, -0.338320769942518, 0.462387777762292, 0.239598554061257, 0.0986979012610507, 0.363786969611213, 0.0907941719789316, -0.551599533260813, -0.617800855762348, -0.991389847235408, -0.311169353699879, 1.46817697209427, -0.470400525259478, 0.207971241929242, 0.0257905801985591, 0.403992960255733, 0.251412098239705, -0.018306777944153, 0.277837575558899, -0.110473910188767, 0.0669280749146731, 0.128539358273528, -0.189114843888824, 0.133558376740387, -0.0210530534538215, 149.62], 0.0)\n"
     ]
    }
   ],
   "source": [
    "# Parse each line into features and label\n",
    "def parse_line(line):\n",
    "    try:\n",
    "        parts = [float(x.strip().replace('\"', '')) for x in line.split(\",\")]\n",
    "        features = parts[:-1]  # All columns except the last one\n",
    "        label = parts[-1]      # Last column is the label (Class)\n",
    "        return (features, label)\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "parsed_data_rdd = data_rdd_raw.map(parse_line).filter(lambda x: x is not None).cache()\n",
    "num_features = len(parsed_data_rdd.first()[0])\n",
    "total_count = parsed_data_rdd.count()\n",
    "\n",
    "print(f\"Total valid records: {total_count}\")\n",
    "print(f\"Number of features: {num_features}\")\n",
    "\n",
    "# Check class distribution (important for imbalanced dataset)\n",
    "class_counts = parsed_data_rdd.map(lambda x: (x[1], 1)).reduceByKey(lambda a, b: a + b).collectAsMap()\n",
    "print(f\"Class distribution: {class_counts}\")\n",
    "print(f\"Percentage of fraudulent transactions: {class_counts.get(1.0, 0)/total_count*100:.4f}%\")\n",
    "\n",
    "# Show a sample record\n",
    "print(\"\\nSample record (features, label):\")\n",
    "print(parsed_data_rdd.first())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling\n",
    "We apply min-max normalization to scale features to the [0,1] range for faster convergence:\n",
    "- Compute min and max for each feature using RDD operations.\n",
    "- Broadcast min/max values to all worker nodes for efficiency.\n",
    "- Normalize features and cache the scaled RDD.\n",
    "- Print a sample scaled record and unpersist the unscaled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T13:43:27.683723Z",
     "iopub.status.busy": "2025-04-11T13:43:27.683368Z",
     "iopub.status.idle": "2025-04-11T13:43:33.361331Z",
     "shell.execute_reply": "2025-04-11T13:43:33.360337Z",
     "shell.execute_reply.started": "2025-04-11T13:43:27.683690Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Scaled Record (Features, Label):\n",
      "([0.0, 0.9351923374337303, 0.7664904186403037, 0.8813649032863348, 0.31302265906669463, 0.7634387348529242, 0.2676686424971201, 0.26681517599177856, 0.7864441979341067, 0.4753117341039581, 0.5106004821833838, 0.25248431906394647, 0.6809076254567205, 0.3715906024604766, 0.6355905300192973, 0.4460836956482719, 0.4343923913601106, 0.7371725526870235, 0.6550658609829579, 0.5948632283047696, 0.5829422304973765, 0.5611843885604425, 0.5229921162596571, 0.6637929753279846, 0.3912526763768729, 0.5851217945036548, 0.39455679156287454, 0.4189761351972912, 0.3126966335786978, 0.0058237930868049554], 0.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PythonRDD[4] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collect min and max for each feature using mapPartitions for better performance\n",
    "def compute_min_max(iterator):\n",
    "    local_min_max = ([float('inf')] * num_features, [float('-inf')] * num_features)\n",
    "    for record in iterator:\n",
    "        features = record[0]\n",
    "        for i in range(num_features):\n",
    "            local_min_max[0][i] = min(local_min_max[0][i], features[i])\n",
    "            local_min_max[1][i] = max(local_min_max[1][i], features[i])\n",
    "    yield local_min_max\n",
    "\n",
    "# Aggregate min/max across all partitions\n",
    "min_max_stats = parsed_data_rdd.mapPartitions(compute_min_max).reduce(\n",
    "    lambda x, y: (\n",
    "        [min(x[0][i], y[0][i]) for i in range(num_features)],\n",
    "        [max(x[1][i], y[1][i]) for i in range(num_features)]\n",
    "    )\n",
    ")\n",
    "\n",
    "min_features = min_max_stats[0]\n",
    "max_features = min_max_stats[1]\n",
    "\n",
    "# Calculate feature ranges, ensuring no division by zero\n",
    "epsilon = 1e-8  # Small value to prevent division by zero\n",
    "feature_ranges = []\n",
    "for i in range(num_features):\n",
    "    range_val = max_features[i] - min_features[i]\n",
    "    feature_ranges.append(max(range_val, epsilon))\n",
    "\n",
    "# Broadcast min, max, and ranges to all worker nodes\n",
    "bc_min_features = sc.broadcast(min_features)\n",
    "bc_max_features = sc.broadcast(max_features)\n",
    "bc_feature_ranges = sc.broadcast(feature_ranges)\n",
    "\n",
    "# Scale the features using min-max normalization\n",
    "def scale_record(record):\n",
    "    features, label = record\n",
    "    scaled_features = []\n",
    "    for i in range(len(features)):\n",
    "        scaled_val = (features[i] - bc_min_features.value[i]) / bc_feature_ranges.value[i]\n",
    "        scaled_features.append(scaled_val)\n",
    "    return (scaled_features, label)\n",
    "\n",
    "scaled_data_rdd = parsed_data_rdd.map(scale_record).cache()\n",
    "\n",
    "print(\"Sample Scaled Record (Features, Label):\")\n",
    "print(scaled_data_rdd.first())\n",
    "\n",
    "# Unpersist the unscaled data\n",
    "parsed_data_rdd.unpersist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split and Class Weighting\n",
    "We prepare the data for training by:\n",
    "- Splitting the scaled data into training (80%) and test (20%) sets with a fixed seed for reproducibility.\n",
    "- Caching the split RDDs for efficiency.\n",
    "- Calculating class weights to handle imbalance (higher weight for the minority class, fraud).\n",
    "- Broadcasting class weights to all worker nodes.\n",
    "- Printing the sizes of the split sets and class weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T13:43:33.366402Z",
     "iopub.status.busy": "2025-04-11T13:43:33.366020Z",
     "iopub.status.idle": "2025-04-11T13:43:44.052430Z",
     "shell.execute_reply": "2025-04-11T13:43:44.051289Z",
     "shell.execute_reply.started": "2025-04-11T13:43:33.366366Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 228163\n",
      "Test set size: 56644\n",
      "Class distribution in training set - 0: 227769, 1: 394\n",
      "Class weights - 0: 0.5009, 1: 289.5470\n"
     ]
    }
   ],
   "source": [
    "# Randomly split data into training (80%) and testing (20%) sets\n",
    "train_rdd, test_rdd = scaled_data_rdd.randomSplit([0.8, 0.2], seed=42)\n",
    "train_rdd.cache()\n",
    "test_rdd.cache()\n",
    "\n",
    "train_count = train_rdd.count()\n",
    "test_count = test_rdd.count()\n",
    "print(f\"Training set size: {train_count}\")\n",
    "print(f\"Test set size: {test_count}\")\n",
    "\n",
    "# Unpersist the full scaled data RDD\n",
    "scaled_data_rdd.unpersist()\n",
    "\n",
    "# Calculate class weights on the training data\n",
    "train_class_counts = train_rdd.map(lambda x: (x[1], 1)).reduceByKey(lambda a, b: a + b).collectAsMap()\n",
    "count_class_0 = train_class_counts.get(0.0, 0)\n",
    "count_class_1 = train_class_counts.get(1.0, 0)\n",
    "\n",
    "# Compute weights: larger weight for the minority class\n",
    "total = count_class_0 + count_class_1\n",
    "if count_class_0 == 0 or count_class_1 == 0:\n",
    "    print(\"Warning: One class is missing in the training set. Using equal weights.\")\n",
    "    class_weights = {0.0: 1.0, 1.0: 1.0}\n",
    "else:\n",
    "    # Simple inverse frequency weighting\n",
    "    class_weights = {\n",
    "        0.0: total / (2.0 * count_class_0),\n",
    "        1.0: total / (2.0 * count_class_1)\n",
    "    }\n",
    "\n",
    "print(f\"Class distribution in training set - 0: {count_class_0}, 1: {count_class_1}\")\n",
    "print(f\"Class weights - 0: {class_weights[0.0]:.4f}, 1: {class_weights[1.0]:.4f}\")\n",
    "\n",
    "# Broadcast class weights to all worker nodes\n",
    "bc_class_weights = sc.broadcast(class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Helper Functions\n",
    "We define core functions for logistic regression:\n",
    "- `sigmoid`: Computes the sigmoid function with overflow protection.\n",
    "- `dot_product`: Calculates the dot product of two vectors.\n",
    "- `predict`: Predicts probabilities using weights and sigmoid.\n",
    "- `compute_gradient_and_loss`: Computes the gradient and loss for a single record, including L2 regularization and class weighting.\n",
    "These functions are essential for the gradient descent implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T13:43:44.054079Z",
     "iopub.status.busy": "2025-04-11T13:43:44.053716Z",
     "iopub.status.idle": "2025-04-11T13:43:44.063335Z",
     "shell.execute_reply": "2025-04-11T13:43:44.062244Z",
     "shell.execute_reply.started": "2025-04-11T13:43:44.054041Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"Sigmoid function with simple overflow protection\"\"\"\n",
    "    if z < -500:\n",
    "        return 0.0\n",
    "    elif z > 500:\n",
    "        return 1.0\n",
    "    else:\n",
    "        return 1.0 / (1.0 + math.exp(-z))\n",
    "\n",
    "def dot_product(vec1, vec2):\n",
    "    \"\"\"Compute dot product of two vectors (lists)\"\"\"\n",
    "    return sum(v1 * v2 for v1, v2 in zip(vec1, vec2))\n",
    "\n",
    "def predict(features, weights):\n",
    "    \"\"\"Predict probability using dot product and sigmoid\"\"\"\n",
    "    # Add a 1.0 for the bias term\n",
    "    features_with_bias = [1.0] + features\n",
    "    z = dot_product(features_with_bias, weights)\n",
    "    return sigmoid(z)\n",
    "\n",
    "def compute_gradient_and_loss(record, weights, reg_param):\n",
    "    \"\"\"Compute gradient and loss for a single record with regularization\"\"\"\n",
    "    features, label = record\n",
    "    features_with_bias = [1.0] + features  # Add bias term\n",
    "    \n",
    "    # Compute prediction\n",
    "    prediction = predict(features, weights)\n",
    "    \n",
    "    # Get the weight for this class\n",
    "    class_weight = bc_class_weights.value.get(label, 1.0)\n",
    "    \n",
    "    # Compute error\n",
    "    error = prediction - label\n",
    "    \n",
    "    # Compute gradient for each feature\n",
    "    gradient = [class_weight * error * x for x in features_with_bias]\n",
    "    \n",
    "    # Add L2 regularization to all weights except bias\n",
    "    for i in range(1, len(weights)):\n",
    "        gradient[i] += reg_param * weights[i]\n",
    "    \n",
    "    # Compute log loss with epsilon to avoid log(0)\n",
    "    epsilon = 1e-9\n",
    "    if label == 1.0:\n",
    "        loss = -class_weight * math.log(prediction + epsilon)\n",
    "    else:\n",
    "        loss = -class_weight * math.log(1 - prediction + epsilon)\n",
    "        \n",
    "    # Add L2 regularization term to loss (exclude bias term)\n",
    "    reg_loss = 0.0\n",
    "    for i in range(1, len(weights)):\n",
    "        reg_loss += 0.5 * reg_param * (weights[i] ** 2)\n",
    "        \n",
    "    return (gradient, loss + reg_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent Implementation with Hyperparameter Tuning\n",
    "This section implements the gradient descent algorithm from scratch for logistic regression and enhances it with hyperparameter tuning to optimize performance. We initialize weights (including bias term) to zeros and use L2 regularization to prevent overfitting. A grid search tests combinations of learning rates (0.01, 0.1, 0.5) and regularization parameters (0.001, 0.01, 0.1), training each model with early stopping based on a convergence threshold. Models are evaluated on the test set using AUC, suitable for the imbalanced dataset, and the best model (highest AUC) is selected. The best model's weights and performance are reported for further evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T13:43:44.064931Z",
     "iopub.status.busy": "2025-04-11T13:43:44.064571Z",
     "iopub.status.idle": "2025-04-11T13:58:50.009468Z",
     "shell.execute_reply": "2025-04-11T13:58:50.008337Z",
     "shell.execute_reply.started": "2025-04-11T13:43:44.064895Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Logistic Regression with Hyperparameter Tuning...\n",
      "\n",
      "Testing learning_rate=0.01, reg_param=0.001\n",
      "Iteration 1/30 | Loss: 0.693147 | Change: inf | Time: 3.22s\n",
      "Iteration 5/30 | Loss: 0.692325 | Change: 0.000204 | Time: 3.27s\n",
      "Iteration 10/30 | Loss: 0.691323 | Change: 0.000198 | Time: 3.34s\n",
      "Iteration 15/30 | Loss: 0.690347 | Change: 0.000194 | Time: 3.27s\n",
      "Iteration 20/30 | Loss: 0.689390 | Change: 0.000190 | Time: 3.33s\n",
      "Iteration 25/30 | Loss: 0.688450 | Change: 0.000187 | Time: 3.26s\n",
      "Iteration 30/30 | Loss: 0.687524 | Change: 0.000184 | Time: 3.24s\n",
      "AUC on test set: 0.9593\n",
      "\n",
      "Testing learning_rate=0.01, reg_param=0.01\n",
      "Iteration 1/30 | Loss: 0.693147 | Change: inf | Time: 3.11s\n",
      "Iteration 5/30 | Loss: 0.692325 | Change: 0.000204 | Time: 3.32s\n",
      "Iteration 10/30 | Loss: 0.691325 | Change: 0.000198 | Time: 3.27s\n",
      "Iteration 15/30 | Loss: 0.690350 | Change: 0.000193 | Time: 3.27s\n",
      "Iteration 20/30 | Loss: 0.689397 | Change: 0.000189 | Time: 3.33s\n",
      "Iteration 25/30 | Loss: 0.688460 | Change: 0.000186 | Time: 3.35s\n",
      "Iteration 30/30 | Loss: 0.687538 | Change: 0.000183 | Time: 3.27s\n",
      "AUC on test set: 0.9593\n",
      "\n",
      "Testing learning_rate=0.01, reg_param=0.1\n",
      "Iteration 1/30 | Loss: 0.693147 | Change: inf | Time: 3.19s\n",
      "Iteration 5/30 | Loss: 0.692327 | Change: 0.000202 | Time: 3.78s\n",
      "Iteration 10/30 | Loss: 0.691339 | Change: 0.000195 | Time: 3.31s\n",
      "Iteration 15/30 | Loss: 0.690384 | Change: 0.000189 | Time: 3.87s\n",
      "Iteration 20/30 | Loss: 0.689457 | Change: 0.000183 | Time: 3.34s\n",
      "Iteration 25/30 | Loss: 0.688556 | Change: 0.000178 | Time: 3.83s\n",
      "Iteration 30/30 | Loss: 0.687676 | Change: 0.000174 | Time: 3.29s\n",
      "AUC on test set: 0.9593\n",
      "\n",
      "Testing learning_rate=0.1, reg_param=0.001\n",
      "Iteration 1/30 | Loss: 0.693147 | Change: inf | Time: 3.25s\n",
      "Iteration 5/30 | Loss: 0.685493 | Change: 0.001816 | Time: 3.41s\n",
      "Iteration 10/30 | Loss: 0.676773 | Change: 0.001709 | Time: 3.30s\n",
      "Iteration 15/30 | Loss: 0.668428 | Change: 0.001643 | Time: 3.26s\n",
      "Iteration 20/30 | Loss: 0.660398 | Change: 0.001582 | Time: 3.26s\n",
      "Iteration 25/30 | Loss: 0.652666 | Change: 0.001523 | Time: 3.31s\n",
      "Iteration 30/30 | Loss: 0.645220 | Change: 0.001467 | Time: 3.26s\n",
      "AUC on test set: 0.9613\n",
      "\n",
      "Testing learning_rate=0.1, reg_param=0.01\n",
      "Iteration 1/30 | Loss: 0.693147 | Change: inf | Time: 3.19s\n",
      "Iteration 5/30 | Loss: 0.685516 | Change: 0.001805 | Time: 3.25s\n",
      "Iteration 10/30 | Loss: 0.676894 | Change: 0.001684 | Time: 3.30s\n",
      "Iteration 15/30 | Loss: 0.668715 | Change: 0.001605 | Time: 3.22s\n",
      "Iteration 20/30 | Loss: 0.660914 | Change: 0.001531 | Time: 3.25s\n",
      "Iteration 25/30 | Loss: 0.653470 | Change: 0.001461 | Time: 3.28s\n",
      "Iteration 30/30 | Loss: 0.646365 | Change: 0.001395 | Time: 3.30s\n",
      "AUC on test set: 0.9613\n",
      "\n",
      "Testing learning_rate=0.1, reg_param=0.1\n",
      "Iteration 1/30 | Loss: 0.693147 | Change: inf | Time: 3.24s\n",
      "Iteration 5/30 | Loss: 0.685749 | Change: 0.001701 | Time: 3.24s\n",
      "Iteration 10/30 | Loss: 0.678042 | Change: 0.001452 | Time: 3.30s\n",
      "Iteration 15/30 | Loss: 0.671357 | Change: 0.001265 | Time: 3.27s\n",
      "Iteration 20/30 | Loss: 0.665525 | Change: 0.001104 | Time: 3.24s\n",
      "Iteration 25/30 | Loss: 0.660433 | Change: 0.000964 | Time: 3.30s\n",
      "Iteration 30/30 | Loss: 0.655988 | Change: 0.000842 | Time: 3.25s\n",
      "AUC on test set: 0.9612\n",
      "\n",
      "Testing learning_rate=0.5, reg_param=0.001\n",
      "Iteration 1/30 | Loss: 0.693147 | Change: inf | Time: 3.21s\n",
      "Iteration 5/30 | Loss: 0.658587 | Change: 0.008023 | Time: 3.31s\n",
      "Iteration 10/30 | Loss: 0.622732 | Change: 0.006644 | Time: 3.33s\n",
      "Iteration 15/30 | Loss: 0.592910 | Change: 0.005546 | Time: 3.25s\n",
      "Iteration 20/30 | Loss: 0.567871 | Change: 0.004676 | Time: 3.24s\n",
      "Iteration 25/30 | Loss: 0.546623 | Change: 0.003987 | Time: 3.32s\n",
      "Iteration 30/30 | Loss: 0.528391 | Change: 0.003436 | Time: 3.24s\n",
      "AUC on test set: 0.9634\n",
      "\n",
      "Testing learning_rate=0.5, reg_param=0.01\n",
      "Iteration 1/30 | Loss: 0.693147 | Change: inf | Time: 3.71s\n",
      "Iteration 5/30 | Loss: 0.659110 | Change: 0.007789 | Time: 3.25s\n",
      "Iteration 10/30 | Loss: 0.625207 | Change: 0.006165 | Time: 3.30s\n",
      "Iteration 15/30 | Loss: 0.598262 | Change: 0.004916 | Time: 3.25s\n",
      "Iteration 20/30 | Loss: 0.576655 | Change: 0.003958 | Time: 3.23s\n",
      "Iteration 25/30 | Loss: 0.559155 | Change: 0.003220 | Time: 3.31s\n",
      "Iteration 30/30 | Loss: 0.544837 | Change: 0.002645 | Time: 3.24s\n",
      "AUC on test set: 0.9633\n",
      "\n",
      "Testing learning_rate=0.5, reg_param=0.1\n",
      "Iteration 1/30 | Loss: 0.693147 | Change: inf | Time: 3.54s\n",
      "Iteration 5/30 | Loss: 0.663854 | Change: 0.005758 | Time: 3.23s\n",
      "Iteration 10/30 | Loss: 0.644526 | Change: 0.002875 | Time: 3.44s\n",
      "Iteration 15/30 | Loss: 0.634804 | Change: 0.001456 | Time: 3.29s\n",
      "Iteration 20/30 | Loss: 0.629826 | Change: 0.000754 | Time: 3.52s\n",
      "Iteration 25/30 | Loss: 0.627206 | Change: 0.000403 | Time: 3.27s\n",
      "Iteration 30/30 | Loss: 0.625769 | Change: 0.000226 | Time: 3.62s\n",
      "AUC on test set: 0.9629\n",
      "\n",
      "--- Best Model ---\n",
      "Best learning_rate: 0.5, reg_param: 0.001\n",
      "Best AUC: 0.9634\n",
      "Final Weights: [0.1830546977463707, -0.11838603726253982, -0.06760194509048988, 0.2547186164844601, -0.21331068394906214, 0.6676496237797149, 0.08065942330145387, 0.005440992639919822, -0.05169140970521707, 0.1449051821912893, -0.18053865444315423, -0.25758781397996355, 0.7318980710463681, -0.5750758893456556, 0.02986779604802562, -0.606852961305054, 0.04199920957631534, -0.2994060613135832, -0.4172048873115122, -0.3098363745085256, 0.23411041976200142, 0.11827687000366927, 0.14104265342144523, 0.08570475531651121, 0.1180203798421748, 0.018264136869969992, 0.1156888592944205, 0.09044294881313987, 0.0860869721085755, 0.06326309300306056, 0.005912445908994038]\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "import time\n",
    "import math\n",
    "\n",
    "# Initialize weights (including bias term)\n",
    "num_features_with_bias = num_features + 1  # Add 1 for bias term\n",
    "initial_weights = [0.0] * num_features_with_bias\n",
    "\n",
    "# Define hyperparameter grid\n",
    "learning_rates = [0.01, 0.1, 0.5]\n",
    "reg_params = [0.001, 0.01, 0.1]\n",
    "max_iterations = 30\n",
    "tolerance = 1e-4  # Convergence threshold\n",
    "\n",
    "# Function to compute AUC (reusing from Cell 11 for validation)\n",
    "def calculate_auc_approximation(data_rdd, weights):\n",
    "    def get_prediction_score(record):\n",
    "        features, actual_label = record\n",
    "        prob = predict(features, weights)\n",
    "        return (prob, actual_label)\n",
    "    \n",
    "    pred_scores = data_rdd.map(get_prediction_score).collect()\n",
    "    pred_scores.sort(key=lambda x: x[0], reverse=True)\n",
    "    \n",
    "    num_positive = sum(1 for _, label in pred_scores if label == 1.0)\n",
    "    num_negative = len(pred_scores) - num_positive\n",
    "    \n",
    "    if num_positive == 0 or num_negative == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    auc = 0.0\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    prev_fp = 0\n",
    "    prev_tp = 0\n",
    "    \n",
    "    for prob, label in pred_scores:\n",
    "        if label == 1.0:\n",
    "            tp += 1\n",
    "        else:\n",
    "            fp += 1\n",
    "        if fp > prev_fp:\n",
    "            auc += (tp + prev_tp) * (fp - prev_fp) / (2.0 * num_positive * num_negative)\n",
    "            prev_fp = fp\n",
    "            prev_tp = tp\n",
    "    \n",
    "    return auc\n",
    "\n",
    "# Gradient descent function (extracted for reuse)\n",
    "def run_gradient_descent(train_rdd, initial_weights, learning_rate, reg_param, max_iterations, tolerance):\n",
    "    current_weights = initial_weights.copy()\n",
    "    previous_loss = float('inf')\n",
    "    iteration_stats = []\n",
    "    \n",
    "    for iteration in range(max_iterations):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        def process_partition(iterator):\n",
    "            local_gradients = [0.0] * num_features_with_bias\n",
    "            local_loss = 0.0\n",
    "            local_count = 0\n",
    "            \n",
    "            for record in iterator:\n",
    "                grad, loss = compute_gradient_and_loss(record, current_weights, reg_param)\n",
    "                local_gradients = [local_gradients[i] + grad[i] for i in range(num_features_with_bias)]\n",
    "                local_loss += loss\n",
    "                local_count += 1\n",
    "            \n",
    "            yield (local_gradients, local_loss, local_count)\n",
    "        \n",
    "        result = train_rdd.mapPartitions(process_partition).reduce(\n",
    "            lambda x, y: (\n",
    "                [x[0][i] + y[0][i] for i in range(num_features_with_bias)],\n",
    "                x[1] + y[1],\n",
    "                x[2] + y[2]\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        total_gradients, total_loss, count = result\n",
    "        avg_gradients = [g / count for g in total_gradients]\n",
    "        avg_loss = total_loss / count\n",
    "        \n",
    "        for i in range(num_features_with_bias):\n",
    "            current_weights[i] -= learning_rate * avg_gradients[i]\n",
    "        \n",
    "        elapsed_time = time.time() - start_time\n",
    "        loss_change = abs(avg_loss - previous_loss)\n",
    "        iteration_stats.append((iteration+1, avg_loss, loss_change, elapsed_time))\n",
    "        \n",
    "        if (iteration+1) % 5 == 0 or iteration == 0 or iteration == max_iterations-1:\n",
    "            print(f\"Iteration {iteration+1}/{max_iterations} | Loss: {avg_loss:.6f} | Change: {loss_change:.6f} | Time: {elapsed_time:.2f}s\")\n",
    "        \n",
    "        if loss_change < tolerance:\n",
    "            print(f\"Converged at iteration {iteration+1}. Loss change below tolerance ({tolerance}).\")\n",
    "            break\n",
    "        \n",
    "        previous_loss = avg_loss\n",
    "    \n",
    "    return current_weights, iteration_stats\n",
    "\n",
    "# Hyperparameter tuning loop\n",
    "print(\"\\nStarting Logistic Regression with Hyperparameter Tuning...\")\n",
    "best_auc = 0.0\n",
    "best_weights = None\n",
    "best_params = None\n",
    "best_stats = None\n",
    "\n",
    "for lr, reg in product(learning_rates, reg_params):\n",
    "    print(f\"\\nTesting learning_rate={lr}, reg_param={reg}\")\n",
    "    weights, stats = run_gradient_descent(train_rdd, initial_weights, lr, reg, max_iterations, tolerance)\n",
    "    \n",
    "    # Evaluate on test set (used as validation here)\n",
    "    auc = calculate_auc_approximation(test_rdd, weights)\n",
    "    print(f\"AUC on test set: {auc:.4f}\")\n",
    "    \n",
    "    if auc > best_auc:\n",
    "        best_auc = auc\n",
    "        best_weights = weights\n",
    "        best_params = (lr, reg)\n",
    "        best_stats = stats\n",
    "\n",
    "# Report best model\n",
    "print(\"\\n--- Best Model ---\")\n",
    "print(f\"Best learning_rate: {best_params[0]}, reg_param: {best_params[1]}\")\n",
    "print(f\"Best AUC: {best_auc:.4f}\")\n",
    "print(f\"Final Weights: {best_weights}\")\n",
    "\n",
    "# Use best weights for subsequent evaluation\n",
    "current_weights = best_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "We evaluate the model on the test set using a threshold of 0.5:\n",
    "- Compute the confusion matrix (TP, FP, TN, FN).\n",
    "- Calculate accuracy, precision, recall, and F1-score.\n",
    "- Print the results, focusing on recall (sensitivity) as it's critical for fraud detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T13:58:50.010964Z",
     "iopub.status.busy": "2025-04-11T13:58:50.010625Z",
     "iopub.status.idle": "2025-04-11T13:58:52.206768Z",
     "shell.execute_reply": "2025-04-11T13:58:52.205693Z",
     "shell.execute_reply.started": "2025-04-11T13:58:50.010935Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Model on Test Set ---\n",
      "Results with threshold=0.5:\n",
      "Accuracy:  0.9993\n",
      "Precision: 0.8427\n",
      "Recall:    0.7653 (Sensitivity)\n",
      "F1-Score:  0.8021\n",
      "Confusion Matrix:\n",
      "  True Positives:  75\n",
      "  False Positives: 14\n",
      "  True Negatives:  56532\n",
      "  False Negatives: 23\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(test_data, weights, threshold=0.5):\n",
    "    \"\"\"Evaluate the model on test data\"\"\"\n",
    "    # Function to predict and compare with actual label\n",
    "    def predict_and_evaluate(record):\n",
    "        features, actual_label = record\n",
    "        prob = predict(features, weights)\n",
    "        predicted_label = 1.0 if prob >= threshold else 0.0\n",
    "        return (predicted_label, actual_label, prob)\n",
    "    \n",
    "    # Get predictions for all test records\n",
    "    predictions = test_data.map(predict_and_evaluate)\n",
    "    predictions.cache()\n",
    "    \n",
    "    # Calculate confusion matrix counts\n",
    "    tp = predictions.filter(lambda x: x[0] == 1.0 and x[1] == 1.0).count()\n",
    "    fp = predictions.filter(lambda x: x[0] == 1.0 and x[1] == 0.0).count()\n",
    "    tn = predictions.filter(lambda x: x[0] == 0.0 and x[1] == 0.0).count()\n",
    "    fn = predictions.filter(lambda x: x[0] == 0.0 and x[1] == 1.0).count()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    total = tp + tn + fp + fn\n",
    "    accuracy = (tp + tn) / total if total > 0 else 0\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    # Unpersist predictions RDD\n",
    "    predictions.unpersist()\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1,\n",
    "        \"confusion_matrix\": {\"tp\": tp, \"fp\": fp, \"tn\": tn, \"fn\": fn}\n",
    "    }\n",
    "\n",
    "# Evaluate model with default threshold of 0.5\n",
    "print(\"\\n--- Evaluating Model on Test Set ---\")\n",
    "evaluation = evaluate_model(test_rdd, current_weights, threshold=0.5)\n",
    "\n",
    "print(\"Results with threshold=0.5:\")\n",
    "print(f\"Accuracy:  {evaluation['accuracy']:.4f}\")\n",
    "print(f\"Precision: {evaluation['precision']:.4f}\")\n",
    "print(f\"Recall:    {evaluation['recall']:.4f} (Sensitivity)\")\n",
    "print(f\"F1-Score:  {evaluation['f1_score']:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(f\"  True Positives:  {evaluation['confusion_matrix']['tp']}\")\n",
    "print(f\"  False Positives: {evaluation['confusion_matrix']['fp']}\")\n",
    "print(f\"  True Negatives:  {evaluation['confusion_matrix']['tn']}\")\n",
    "print(f\"  False Negatives: {evaluation['confusion_matrix']['fn']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threshold Tuning and AUC Calculation\n",
    "We explore model performance further:\n",
    "- Test different decision thresholds (0.1 to 0.9) to balance precision and recall, as the default 0.5 may not be optimal for imbalanced data.\n",
    "- Calculate the Area Under the ROC Curve (AUC) using an approximation with the trapezoidal rule, a key metric for imbalanced datasets.\n",
    "- Print the results for each threshold and the AUC value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T13:58:52.208127Z",
     "iopub.status.busy": "2025-04-11T13:58:52.207771Z",
     "iopub.status.idle": "2025-04-11T13:59:03.785552Z",
     "shell.execute_reply": "2025-04-11T13:59:03.784516Z",
     "shell.execute_reply.started": "2025-04-11T13:58:52.208100Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Different Thresholds ---\n",
      "Threshold=0.1 | Precision: 0.0017 | Recall: 1.0000 | F1: 0.0035\n",
      "Threshold=0.3 | Precision: 0.0017 | Recall: 1.0000 | F1: 0.0035\n",
      "Threshold=0.5 | Precision: 0.8427 | Recall: 0.7653 | F1: 0.8021\n",
      "Threshold=0.7 | Precision: 0.8571 | Recall: 0.2449 | F1: 0.3810\n",
      "Threshold=0.9 | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000\n",
      "\n",
      "--- AUC Approximation ---\n",
      "Area Under ROC Curve (AUC): 0.9634\n"
     ]
    }
   ],
   "source": [
    "# Try different thresholds to find better precision-recall balance\n",
    "print(\"\\n--- Evaluating Different Thresholds ---\")\n",
    "thresholds = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "for threshold in thresholds:\n",
    "    eval_result = evaluate_model(test_rdd, current_weights, threshold)\n",
    "    print(f\"Threshold={threshold:.1f} | Precision: {eval_result['precision']:.4f} | Recall: {eval_result['recall']:.4f} | F1: {eval_result['f1_score']:.4f}\")\n",
    "\n",
    "# Calculate AUC\n",
    "def calculate_auc_approximation(test_data, weights):\n",
    "    \"\"\"Calculate an approximation of the AUC using discrete thresholds\"\"\"\n",
    "    # Function to get prediction probabilities and actual labels\n",
    "    def get_prediction_score(record):\n",
    "        features, actual_label = record\n",
    "        prob = predict(features, weights)\n",
    "        return (prob, actual_label)\n",
    "    \n",
    "    # Get prediction scores and sort them\n",
    "    pred_scores = test_data.map(get_prediction_score).collect()\n",
    "    pred_scores.sort(key=lambda x: x[0], reverse=True)\n",
    "    \n",
    "    # Initialize counters\n",
    "    num_positive = sum(1 for _, label in pred_scores if label == 1.0)\n",
    "    num_negative = len(pred_scores) - num_positive\n",
    "    \n",
    "    if num_positive == 0 or num_negative == 0:\n",
    "        print(\"Warning: Only one class present in test set. AUC calculation not possible.\")\n",
    "        return 0.0\n",
    "    \n",
    "    # Initialize the area\n",
    "    auc = 0.0\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    prev_fp = 0\n",
    "    prev_tp = 0\n",
    "    \n",
    "    # Process each prediction\n",
    "    for prob, label in pred_scores:\n",
    "        if label == 1.0:\n",
    "            tp += 1\n",
    "        else:\n",
    "            fp += 1\n",
    "            \n",
    "        # Add trapezoid area under the curve\n",
    "        if fp > prev_fp:\n",
    "            auc += (tp + prev_tp) * (fp - prev_fp) / (2.0 * num_positive * num_negative)\n",
    "            prev_fp = fp\n",
    "            prev_tp = tp\n",
    "    \n",
    "    return auc\n",
    "\n",
    "print(\"\\n--- AUC Approximation ---\")\n",
    "auc = calculate_auc_approximation(test_rdd, current_weights)\n",
    "print(f\"Area Under ROC Curve (AUC): {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup and Shutdown\n",
    "We clean up resources to free memory and stop the Spark session:\n",
    "- Unpersist cached RDDs (`train_rdd`, `test_rdd`).\n",
    "- Unpersist broadcast variables.\n",
    "- Stop the Spark session to ensure proper shutdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T13:59:03.786859Z",
     "iopub.status.busy": "2025-04-11T13:59:03.786569Z",
     "iopub.status.idle": "2025-04-11T13:59:04.697285Z",
     "shell.execute_reply": "2025-04-11T13:59:04.696225Z",
     "shell.execute_reply.started": "2025-04-11T13:59:03.786833Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Stopping Spark Session ---\n"
     ]
    }
   ],
   "source": [
    "# Clean up\n",
    "\n",
    "train_rdd.unpersist()\n",
    "test_rdd.unpersist()\n",
    "bc_min_features.unpersist()\n",
    "bc_max_features.unpersist()\n",
    "bc_feature_ranges.unpersist()\n",
    "bc_class_weights.unpersist()\n",
    "\n",
    "# Stop Spark session\n",
    "print(\"--- Stopping Spark Session ---\")\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 44258,
     "sourceId": 6960,
     "sourceType": "competition"
    },
    {
     "datasetId": 310,
     "sourceId": 23498,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
