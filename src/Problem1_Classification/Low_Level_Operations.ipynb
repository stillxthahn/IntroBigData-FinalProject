{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T16:05:21.258686Z",
     "iopub.status.busy": "2025-04-09T16:05:21.258407Z",
     "iopub.status.idle": "2025-04-09T16:05:28.007073Z",
     "shell.execute_reply": "2025-04-09T16:05:28.006247Z",
     "shell.execute_reply.started": "2025-04-09T16:05:21.258655Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark version: 3.5.3\n",
      "PySpark version: 3.5.3\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import math\n",
    "import time\n",
    "\n",
    "# Create a SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"CreditCardFraud_LowLevel\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "print(f\"Spark version: {spark.version}\")\n",
    "print(f\"PySpark version: {pyspark.__version__}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "Loads the Credit Card Fraud dataset using low-level RDD operations.\n",
    "- Using textFile to read the CSV directly into an RDD\n",
    "- Filtering out the header row to work with only data rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T16:05:28.008677Z",
     "iopub.status.busy": "2025-04-09T16:05:28.008077Z",
     "iopub.status.idle": "2025-04-09T16:05:32.155477Z",
     "shell.execute_reply": "2025-04-09T16:05:32.154639Z",
     "shell.execute_reply.started": "2025-04-09T16:05:28.008651Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of records: 284807\n"
     ]
    }
   ],
   "source": [
    "# 1. Data Loading and Exploration\n",
    "# Path to the credit card dataset in Kaggle\n",
    "credit_card_path = \"/kaggle/input/creditcardfraud/creditcard.csv\"\n",
    "\n",
    "# Load the CSV file as a text file and filter out the header\n",
    "lines_rdd = sc.textFile(credit_card_path)\n",
    "header = lines_rdd.first()\n",
    "data_rdd_raw = lines_rdd.filter(lambda line: line != header)\n",
    "\n",
    "# Quick count of the raw data\n",
    "print(f\"Total number of records: {data_rdd_raw.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Parsing and Initial Analysis\n",
    "Parses the raw text data into features and labels and performs initial analysis.\n",
    "- Converting text lines to tuples of (features, label)\n",
    "- Analyzing class distribution to understand the imbalance\n",
    "- The dataset is known to be highly imbalanced (very few frauds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T16:05:32.156633Z",
     "iopub.status.busy": "2025-04-09T16:05:32.156310Z",
     "iopub.status.idle": "2025-04-09T16:05:37.802440Z",
     "shell.execute_reply": "2025-04-09T16:05:37.801407Z",
     "shell.execute_reply.started": "2025-04-09T16:05:32.156597Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total valid records: 284807\n",
      "Number of features: 30\n",
      "Class distribution: {0.0: 284315, 1.0: 492}\n",
      "Percentage of fraudulent transactions: 0.1727%\n",
      "\n",
      "Sample record (features, label):\n",
      "([0.0, -1.3598071336738, -0.0727811733098497, 2.53634673796914, 1.37815522427443, -0.338320769942518, 0.462387777762292, 0.239598554061257, 0.0986979012610507, 0.363786969611213, 0.0907941719789316, -0.551599533260813, -0.617800855762348, -0.991389847235408, -0.311169353699879, 1.46817697209427, -0.470400525259478, 0.207971241929242, 0.0257905801985591, 0.403992960255733, 0.251412098239705, -0.018306777944153, 0.277837575558899, -0.110473910188767, 0.0669280749146731, 0.128539358273528, -0.189114843888824, 0.133558376740387, -0.0210530534538215, 149.62], 0.0)\n"
     ]
    }
   ],
   "source": [
    "# 2. Data Parsing and Preprocessing\n",
    "# Parse each line into features and label\n",
    "def parse_line(line):\n",
    "    try:\n",
    "        parts = [float(x.strip().replace('\"', '')) for x in line.split(\",\")]\n",
    "        features = parts[:-1]  # All columns except the last one\n",
    "        label = parts[-1]      # Last column is the label (Class)\n",
    "        return (features, label)\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "parsed_data_rdd = data_rdd_raw.map(parse_line).filter(lambda x: x is not None).cache()\n",
    "num_features = len(parsed_data_rdd.first()[0])\n",
    "total_count = parsed_data_rdd.count()\n",
    "\n",
    "print(f\"Total valid records: {total_count}\")\n",
    "print(f\"Number of features: {num_features}\")\n",
    "\n",
    "# Check class distribution (important for imbalanced dataset)\n",
    "class_counts = parsed_data_rdd.map(lambda x: (x[1], 1)).reduceByKey(lambda a, b: a + b).collectAsMap()\n",
    "print(f\"Class distribution: {class_counts}\")\n",
    "print(f\"Percentage of fraudulent transactions: {class_counts.get(1.0, 0)/total_count*100:.4f}%\")\n",
    "\n",
    "# Show a sample record\n",
    "print(\"\\nSample record (features, label):\")\n",
    "print(parsed_data_rdd.first())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling\n",
    "Scales the features using min-max normalization to ensure faster convergence.\n",
    "- Using a custom RDD aggregation to find min and max for each feature\n",
    "- Normalizing all features to [0,1] range\n",
    "- Broadcasting min/max values to all worker nodes for efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T16:05:37.804738Z",
     "iopub.status.busy": "2025-04-09T16:05:37.804454Z",
     "iopub.status.idle": "2025-04-09T16:05:42.026863Z",
     "shell.execute_reply": "2025-04-09T16:05:42.026159Z",
     "shell.execute_reply.started": "2025-04-09T16:05:37.804704Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Scaled Record (Features, Label):\n",
      "([0.0, 0.9351923374337303, 0.7664904186403037, 0.8813649032863348, 0.31302265906669463, 0.7634387348529242, 0.2676686424971201, 0.26681517599177856, 0.7864441979341067, 0.4753117341039581, 0.5106004821833838, 0.25248431906394647, 0.6809076254567205, 0.3715906024604766, 0.6355905300192973, 0.4460836956482719, 0.4343923913601106, 0.7371725526870235, 0.6550658609829579, 0.5948632283047696, 0.5829422304973765, 0.5611843885604425, 0.5229921162596571, 0.6637929753279846, 0.3912526763768729, 0.5851217945036548, 0.39455679156287454, 0.4189761351972912, 0.3126966335786978, 0.0058237930868049554], 0.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PythonRDD[4] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Feature Scaling using Min-Max scaling\n",
    "# Collect min and max for each feature\n",
    "def min_max_aggregator(x, y):\n",
    "    \"\"\"Helper function to aggregate min and max values\"\"\"\n",
    "    mins = []\n",
    "    maxs = []\n",
    "    for i in range(len(x[0])):\n",
    "        mins.append(min(x[0][i], y[0][i]))\n",
    "        maxs.append(max(x[1][i], y[1][i]))\n",
    "    return (mins, maxs)\n",
    "\n",
    "# Initialize min as infinity and max as negative infinity for each feature\n",
    "initial_min_max = ([float('inf')] * num_features, [float('-inf')] * num_features)\n",
    "\n",
    "# Process each partition to get local min/max\n",
    "def compute_min_max(iterator):\n",
    "    local_min_max = ([float('inf')] * num_features, [float('-inf')] * num_features)\n",
    "    for record in iterator:\n",
    "        features = record[0]\n",
    "        for i in range(num_features):\n",
    "            local_min_max[0][i] = min(local_min_max[0][i], features[i])\n",
    "            local_min_max[1][i] = max(local_min_max[1][i], features[i])\n",
    "    yield local_min_max\n",
    "\n",
    "# Aggregate min/max across all partitions\n",
    "min_max_stats = parsed_data_rdd.mapPartitions(compute_min_max).reduce(\n",
    "    lambda x, y: (\n",
    "        [min(x[0][i], y[0][i]) for i in range(num_features)],\n",
    "        [max(x[1][i], y[1][i]) for i in range(num_features)]\n",
    "    )\n",
    ")\n",
    "\n",
    "min_features = min_max_stats[0]\n",
    "max_features = min_max_stats[1]\n",
    "\n",
    "# Calculate feature ranges, ensuring no division by zero\n",
    "epsilon = 1e-8  # Small value to prevent division by zero\n",
    "feature_ranges = []\n",
    "for i in range(num_features):\n",
    "    range_val = max_features[i] - min_features[i]\n",
    "    feature_ranges.append(max(range_val, epsilon))\n",
    "\n",
    "# Broadcast min, max, and ranges to all worker nodes\n",
    "bc_min_features = sc.broadcast(min_features)\n",
    "bc_max_features = sc.broadcast(max_features)\n",
    "bc_feature_ranges = sc.broadcast(feature_ranges)\n",
    "\n",
    "# Scale the features using min-max normalization\n",
    "def scale_record(record):\n",
    "    features, label = record\n",
    "    scaled_features = []\n",
    "    for i in range(len(features)):\n",
    "        scaled_val = (features[i] - bc_min_features.value[i]) / bc_feature_ranges.value[i]\n",
    "        scaled_features.append(scaled_val)\n",
    "    return (scaled_features, label)\n",
    "\n",
    "scaled_data_rdd = parsed_data_rdd.map(scale_record).cache()\n",
    "\n",
    "print(\"Sample Scaled Record (Features, Label):\")\n",
    "print(scaled_data_rdd.first())\n",
    "\n",
    "# Unpersist the unscaled data\n",
    "parsed_data_rdd.unpersist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split\n",
    "Randomly splits the data into training and testing sets.<br>\n",
    "Key points:\n",
    "- Using an 80/20 split, which is standard in machine learning\n",
    "- Setting a fixed random seed (42) for reproducibility of results\n",
    "- Caching the training and test RDDs for multiple uses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T16:05:42.028350Z",
     "iopub.status.busy": "2025-04-09T16:05:42.028071Z",
     "iopub.status.idle": "2025-04-09T16:05:48.752040Z",
     "shell.execute_reply": "2025-04-09T16:05:48.751384Z",
     "shell.execute_reply.started": "2025-04-09T16:05:42.028318Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 228163\n",
      "Test set size: 56644\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PythonRDD[14] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Train-Test Split\n",
    "# Randomly split data into training (80%) and testing (20%) sets\n",
    "train_rdd, test_rdd = scaled_data_rdd.randomSplit([0.8, 0.2], seed=42)\n",
    "train_rdd.cache()\n",
    "test_rdd.cache()\n",
    "\n",
    "train_count = train_rdd.count()\n",
    "test_count = test_rdd.count()\n",
    "print(f\"Training set size: {train_count}\")\n",
    "print(f\"Test set size: {test_count}\")\n",
    "\n",
    "# Unpersist the full scaled data RDD\n",
    "scaled_data_rdd.unpersist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Weighting for Imbalance Handling\n",
    "This section calculates weights for each class to address the extreme imbalance.<br>\n",
    "Key points:\n",
    "- The credit card fraud dataset has very few positive examples (~0.17%)\n",
    "- We compute weights inversely proportional to class frequencies\n",
    "- This ensures the minority class has more impact during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T16:05:48.753220Z",
     "iopub.status.busy": "2025-04-09T16:05:48.752894Z",
     "iopub.status.idle": "2025-04-09T16:05:50.014019Z",
     "shell.execute_reply": "2025-04-09T16:05:50.011801Z",
     "shell.execute_reply.started": "2025-04-09T16:05:48.753189Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution in training set - 0: 227769, 1: 394\n",
      "Class weights - 0: 0.5009, 1: 289.5470\n"
     ]
    }
   ],
   "source": [
    "# 5. Class Weighting for Imbalance Handling\n",
    "# Calculate class weights on the training data\n",
    "train_class_counts = train_rdd.map(lambda x: (x[1], 1)).reduceByKey(lambda a, b: a + b).collectAsMap()\n",
    "count_class_0 = train_class_counts.get(0.0, 0)\n",
    "count_class_1 = train_class_counts.get(1.0, 0)\n",
    "\n",
    "# Compute weights: larger weight for the minority class\n",
    "total = count_class_0 + count_class_1\n",
    "if count_class_0 == 0 or count_class_1 == 0:\n",
    "    print(\"Warning: One class is missing in the training set. Using equal weights.\")\n",
    "    class_weights = {0.0: 1.0, 1.0: 1.0}\n",
    "else:\n",
    "    # Simple inverse frequency weighting\n",
    "    class_weights = {\n",
    "        0.0: total / (2.0 * count_class_0),\n",
    "        1.0: total / (2.0 * count_class_1)\n",
    "    }\n",
    "\n",
    "print(f\"Class distribution in training set - 0: {count_class_0}, 1: {count_class_1}\")\n",
    "print(f\"Class weights - 0: {class_weights[0.0]:.4f}, 1: {class_weights[1.0]:.4f}\")\n",
    "\n",
    "# Broadcast class weights to all worker nodes\n",
    "bc_class_weights = sc.broadcast(class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Helper Functions\n",
    "Defines the core mathematical functions needed for logistic regression.\n",
    "- Sigmoid function with overflow protection for numerical stability\n",
    "- Dot product implementation for vector multiplication\n",
    "- Prediction function to compute probabilities\n",
    "- Gradient and loss computation with L2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T16:05:50.016602Z",
     "iopub.status.busy": "2025-04-09T16:05:50.016300Z",
     "iopub.status.idle": "2025-04-09T16:05:50.029190Z",
     "shell.execute_reply": "2025-04-09T16:05:50.028480Z",
     "shell.execute_reply.started": "2025-04-09T16:05:50.016573Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 6. Logistic Regression Helper Functions\n",
    "def sigmoid(z):\n",
    "    \"\"\"Sigmoid function with simple overflow protection\"\"\"\n",
    "    if z < -500:\n",
    "        return 0.0\n",
    "    elif z > 500:\n",
    "        return 1.0\n",
    "    else:\n",
    "        return 1.0 / (1.0 + math.exp(-z))\n",
    "\n",
    "def dot_product(vec1, vec2):\n",
    "    \"\"\"Compute dot product of two vectors (lists)\"\"\"\n",
    "    return sum(v1 * v2 for v1, v2 in zip(vec1, vec2))\n",
    "\n",
    "def predict(features, weights):\n",
    "    \"\"\"Predict probability using dot product and sigmoid\"\"\"\n",
    "    # Add a 1.0 for the bias term\n",
    "    features_with_bias = [1.0] + features\n",
    "    z = dot_product(features_with_bias, weights)\n",
    "    return sigmoid(z)\n",
    "\n",
    "def compute_gradient_and_loss(record, weights, reg_param):\n",
    "    \"\"\"Compute gradient and loss for a single record with regularization\"\"\"\n",
    "    features, label = record\n",
    "    features_with_bias = [1.0] + features  # Add bias term\n",
    "    \n",
    "    # Compute prediction\n",
    "    prediction = predict(features, weights)\n",
    "    \n",
    "    # Get the weight for this class\n",
    "    class_weight = bc_class_weights.value.get(label, 1.0)\n",
    "    \n",
    "    # Compute error\n",
    "    error = prediction - label\n",
    "    \n",
    "    # Compute gradient for each feature\n",
    "    gradient = [class_weight * error * x for x in features_with_bias]\n",
    "    \n",
    "    # Add L2 regularization to all weights except bias\n",
    "    for i in range(1, len(weights)):\n",
    "        gradient[i] += reg_param * weights[i]\n",
    "    \n",
    "    # Compute log loss with epsilon to avoid log(0)\n",
    "    epsilon = 1e-9\n",
    "    if label == 1.0:\n",
    "        loss = -class_weight * math.log(prediction + epsilon)\n",
    "    else:\n",
    "        loss = -class_weight * math.log(1 - prediction + epsilon)\n",
    "        \n",
    "    # Add L2 regularization term to loss (exclude bias term)\n",
    "    reg_loss = 0.0\n",
    "    for i in range(1, len(weights)):\n",
    "        reg_loss += 0.5 * reg_param * (weights[i] ** 2)\n",
    "        \n",
    "    return (gradient, loss + reg_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent Implementation\n",
    "This section implements the gradient descent algorithm from scratch.\n",
    "Key points:\n",
    "- Initializing weights (including bias term) to zeros\n",
    "- Using L2 regularization to prevent overfitting\n",
    "- Implementing early stopping via convergence check\n",
    "- Training over multiple iterations until convergence or max iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T16:05:50.030085Z",
     "iopub.status.busy": "2025-04-09T16:05:50.029830Z",
     "iopub.status.idle": "2025-04-09T16:07:11.857124Z",
     "shell.execute_reply": "2025-04-09T16:07:11.856111Z",
     "shell.execute_reply.started": "2025-04-09T16:05:50.030061Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Low-Level Logistic Regression Training...\n",
      "Parameters: Learning Rate=0.1, L2 Reg=0.01, Max Iterations=30\n",
      "Iteration 1/30 | Loss: 0.693147 | Change: inf | Time: 2.72s\n",
      "Iteration 5/30 | Loss: 0.685516 | Change: 0.001805 | Time: 2.73s\n",
      "Iteration 10/30 | Loss: 0.676894 | Change: 0.001684 | Time: 2.70s\n",
      "Iteration 15/30 | Loss: 0.668715 | Change: 0.001605 | Time: 2.73s\n",
      "Iteration 20/30 | Loss: 0.660914 | Change: 0.001531 | Time: 2.65s\n",
      "Iteration 25/30 | Loss: 0.653470 | Change: 0.001461 | Time: 2.69s\n",
      "Iteration 30/30 | Loss: 0.646365 | Change: 0.001395 | Time: 2.63s\n",
      "\n",
      "--- Training Complete ---\n",
      "Final Weights: [0.03947948468815749, -0.037282989413460504, -0.021600803207485714, 0.05772032583346549, -0.055090438464675734, 0.15492948283685273, 0.014877842226540526, 0.00034299426982540936, -0.014322963241046502, 0.03251114674977182, -0.04583017470110711, -0.06429836874175747, 0.17263145586944628, -0.140826374351463, 0.008128334722601, -0.1427990825877394, 0.008430017723786612, -0.07566732963769647, -0.10803467730714682, -0.08365193892797336, 0.056323729945503206, 0.025722820072650632, 0.030390954592265595, 0.019091700884870832, 0.02534771047311003, 0.004174182631690978, 0.024796863336296868, 0.020853851370161068, 0.018513053395247895, 0.013495515550566651, 0.0011519612473825573]\n"
     ]
    }
   ],
   "source": [
    "# 7. Gradient Descent Implementation\n",
    "# Initialize weights (including bias term)\n",
    "num_features_with_bias = num_features + 1  # Add 1 for bias term\n",
    "initial_weights = [0.0] * num_features_with_bias\n",
    "\n",
    "# Gradient Descent Parameters\n",
    "learning_rate = 0.1\n",
    "max_iterations = 30\n",
    "reg_param = 0.01  # L2 regularization strength\n",
    "tolerance = 1e-4  # Convergence threshold\n",
    "\n",
    "# Training loop\n",
    "current_weights = initial_weights.copy()\n",
    "previous_loss = float('inf')\n",
    "iteration_stats = []\n",
    "\n",
    "print(f\"\\nStarting Low-Level Logistic Regression Training...\")\n",
    "print(f\"Parameters: Learning Rate={learning_rate}, L2 Reg={reg_param}, Max Iterations={max_iterations}\")\n",
    "\n",
    "for iteration in range(max_iterations):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Process each partition to compute local gradients and losses\n",
    "    def process_partition(iterator):\n",
    "        local_gradients = [0.0] * num_features_with_bias\n",
    "        local_loss = 0.0\n",
    "        local_count = 0\n",
    "        \n",
    "        for record in iterator:\n",
    "            grad, loss = compute_gradient_and_loss(record, current_weights, reg_param)\n",
    "            # Add to local gradient sum\n",
    "            local_gradients = [local_gradients[i] + grad[i] for i in range(num_features_with_bias)]\n",
    "            local_loss += loss\n",
    "            local_count += 1\n",
    "            \n",
    "        yield (local_gradients, local_loss, local_count)\n",
    "    \n",
    "    # Map partitions and reduce results\n",
    "    result = train_rdd.mapPartitions(process_partition).reduce(\n",
    "        lambda x, y: (\n",
    "            [x[0][i] + y[0][i] for i in range(num_features_with_bias)],\n",
    "            x[1] + y[1],\n",
    "            x[2] + y[2]\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    total_gradients, total_loss, count = result\n",
    "    \n",
    "    # Average the gradients and loss\n",
    "    avg_gradients = [g / count for g in total_gradients]\n",
    "    avg_loss = total_loss / count\n",
    "    \n",
    "    # Update weights using gradient descent\n",
    "    for i in range(num_features_with_bias):\n",
    "        current_weights[i] -= learning_rate * avg_gradients[i]\n",
    "    \n",
    "    # Compute time taken\n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    # Check for convergence\n",
    "    loss_change = abs(avg_loss - previous_loss)\n",
    "    iteration_stats.append((iteration+1, avg_loss, loss_change, elapsed_time))\n",
    "    \n",
    "    # Print progress periodically\n",
    "    if (iteration+1) % 5 == 0 or iteration == 0 or iteration == max_iterations-1:\n",
    "        print(f\"Iteration {iteration+1}/{max_iterations} | Loss: {avg_loss:.6f} | Change: {loss_change:.6f} | Time: {elapsed_time:.2f}s\")\n",
    "    \n",
    "    if loss_change < tolerance:\n",
    "        print(f\"\\nConverged at iteration {iteration+1}. Loss change below tolerance ({tolerance}).\")\n",
    "        break\n",
    "        \n",
    "    previous_loss = avg_loss\n",
    "\n",
    "print(\"\\n--- Training Complete ---\")\n",
    "print(f\"Final Weights: {current_weights}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "Evaluates the trained model on the test set:\n",
    "- Computing the confusion matrix (TP, FP, TN, FN)\n",
    "- Calculating key metrics: accuracy, precision, recall, F1 score\n",
    "- Evaluating at a specific probability threshold (default 0.5)\n",
    "- For fraud detection, recall is often more important than precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T16:07:11.858394Z",
     "iopub.status.busy": "2025-04-09T16:07:11.858075Z",
     "iopub.status.idle": "2025-04-09T16:07:13.687305Z",
     "shell.execute_reply": "2025-04-09T16:07:13.686525Z",
     "shell.execute_reply.started": "2025-04-09T16:07:11.858370Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Model on Test Set ---\n",
      "Results with threshold=0.5:\n",
      "Accuracy:  0.9992\n",
      "Precision: 0.8788\n",
      "Recall:    0.5918 (Sensitivity)\n",
      "F1-Score:  0.7073\n",
      "Confusion Matrix:\n",
      "  True Positives:  58\n",
      "  False Positives: 8\n",
      "  True Negatives:  56538\n",
      "  False Negatives: 40\n"
     ]
    }
   ],
   "source": [
    "# 8. Model Evaluation\n",
    "def evaluate_model(test_data, weights, threshold=0.5):\n",
    "    \"\"\"Evaluate the model on test data\"\"\"\n",
    "    # Function to predict and compare with actual label\n",
    "    def predict_and_evaluate(record):\n",
    "        features, actual_label = record\n",
    "        prob = predict(features, weights)\n",
    "        predicted_label = 1.0 if prob >= threshold else 0.0\n",
    "        return (predicted_label, actual_label, prob)\n",
    "    \n",
    "    # Get predictions for all test records\n",
    "    predictions = test_data.map(predict_and_evaluate)\n",
    "    predictions.cache()\n",
    "    \n",
    "    # Calculate confusion matrix counts\n",
    "    tp = predictions.filter(lambda x: x[0] == 1.0 and x[1] == 1.0).count()\n",
    "    fp = predictions.filter(lambda x: x[0] == 1.0 and x[1] == 0.0).count()\n",
    "    tn = predictions.filter(lambda x: x[0] == 0.0 and x[1] == 0.0).count()\n",
    "    fn = predictions.filter(lambda x: x[0] == 0.0 and x[1] == 1.0).count()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    total = tp + tn + fp + fn\n",
    "    accuracy = (tp + tn) / total if total > 0 else 0\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    # Unpersist predictions RDD\n",
    "    predictions.unpersist()\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1,\n",
    "        \"confusion_matrix\": {\"tp\": tp, \"fp\": fp, \"tn\": tn, \"fn\": fn}\n",
    "    }\n",
    "\n",
    "# Evaluate model with default threshold of 0.5\n",
    "print(\"\\n--- Evaluating Model on Test Set ---\")\n",
    "evaluation = evaluate_model(test_rdd, current_weights, threshold=0.5)\n",
    "\n",
    "print(\"Results with threshold=0.5:\")\n",
    "print(f\"Accuracy:  {evaluation['accuracy']:.4f}\")\n",
    "print(f\"Precision: {evaluation['precision']:.4f}\")\n",
    "print(f\"Recall:    {evaluation['recall']:.4f} (Sensitivity)\")\n",
    "print(f\"F1-Score:  {evaluation['f1_score']:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(f\"  True Positives:  {evaluation['confusion_matrix']['tp']}\")\n",
    "print(f\"  False Positives: {evaluation['confusion_matrix']['fp']}\")\n",
    "print(f\"  True Negatives:  {evaluation['confusion_matrix']['tn']}\")\n",
    "print(f\"  False Negatives: {evaluation['confusion_matrix']['fn']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threshold Tuning\n",
    "Explores different decision thresholds to optimize performance.\n",
    "- The default 0.5 threshold may not be optimal for imbalanced data\n",
    "- Adjusting the threshold controls the precision-recall trade-off\n",
    "- Higher thresholds typically increase precision but decrease recall\n",
    "- The optimal threshold depends on the specific business cost of FP vs. FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T16:07:13.688385Z",
     "iopub.status.busy": "2025-04-09T16:07:13.688099Z",
     "iopub.status.idle": "2025-04-09T16:07:22.883610Z",
     "shell.execute_reply": "2025-04-09T16:07:22.882642Z",
     "shell.execute_reply.started": "2025-04-09T16:07:13.688359Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Different Thresholds ---\n",
      "Threshold=0.1 | Precision: 0.0017 | Recall: 1.0000 | F1: 0.0035\n",
      "Threshold=0.3 | Precision: 0.0017 | Recall: 1.0000 | F1: 0.0035\n",
      "Threshold=0.5 | Precision: 0.8788 | Recall: 0.5918 | F1: 0.7073\n",
      "Threshold=0.7 | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000\n",
      "Threshold=0.9 | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# 9. Threshold Tuning for Better Precision/Recall Balance\n",
    "# Try different thresholds to find better precision-recall balance\n",
    "print(\"\\n--- Evaluating Different Thresholds ---\")\n",
    "thresholds = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "for threshold in thresholds:\n",
    "    eval_result = evaluate_model(test_rdd, current_weights, threshold)\n",
    "    print(f\"Threshold={threshold:.1f} | Precision: {eval_result['precision']:.4f} | Recall: {eval_result['recall']:.4f} | F1: {eval_result['f1_score']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUC Calculation\n",
    "Calculates the Area Under the ROC Curve (AUC) metric.<br>\n",
    "Key points:\n",
    "- AUC measures the model's ability to distinguish between classes\n",
    "- An AUC of 0.5 means random guessing, 1.0 is perfect classification\n",
    "- For imbalanced datasets, AUC is more informative than accuracy\n",
    "- We approximate AUC using the trapezoidal rule for efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T16:07:22.884850Z",
     "iopub.status.busy": "2025-04-09T16:07:22.884604Z",
     "iopub.status.idle": "2025-04-09T16:07:23.433423Z",
     "shell.execute_reply": "2025-04-09T16:07:23.432503Z",
     "shell.execute_reply.started": "2025-04-09T16:07:22.884828Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- AUC Approximation ---\n",
      "Area Under ROC Curve (AUC): 0.9613\n"
     ]
    }
   ],
   "source": [
    "# 10. Calculate simple AUC approximation (trapezoidal rule)\n",
    "def calculate_auc_approximation(test_data, weights):\n",
    "    \"\"\"Calculate an approximation of the AUC using discrete thresholds\"\"\"\n",
    "    # Function to get prediction probabilities and actual labels\n",
    "    def get_prediction_score(record):\n",
    "        features, actual_label = record\n",
    "        prob = predict(features, weights)\n",
    "        return (prob, actual_label)\n",
    "    \n",
    "    # Get prediction scores and sort them\n",
    "    pred_scores = test_data.map(get_prediction_score).collect()\n",
    "    pred_scores.sort(key=lambda x: x[0], reverse=True)\n",
    "    \n",
    "    # Initialize counters\n",
    "    num_positive = sum(1 for _, label in pred_scores if label == 1.0)\n",
    "    num_negative = len(pred_scores) - num_positive\n",
    "    \n",
    "    if num_positive == 0 or num_negative == 0:\n",
    "        print(\"Warning: Only one class present in test set. AUC calculation not possible.\")\n",
    "        return 0.0\n",
    "    \n",
    "    # Initialize the area\n",
    "    auc = 0.0\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    prev_fp = 0\n",
    "    prev_tp = 0\n",
    "    \n",
    "    # Process each prediction\n",
    "    for prob, label in pred_scores:\n",
    "        if label == 1.0:\n",
    "            tp += 1\n",
    "        else:\n",
    "            fp += 1\n",
    "            \n",
    "        # Add trapezoid area under the curve\n",
    "        if fp > prev_fp:\n",
    "            auc += (tp + prev_tp) * (fp - prev_fp) / (2.0 * num_positive * num_negative)\n",
    "            prev_fp = fp\n",
    "            prev_tp = tp\n",
    "    \n",
    "    return auc\n",
    "\n",
    "print(\"\\n--- AUC Approximation ---\")\n",
    "auc = calculate_auc_approximation(test_rdd, current_weights)\n",
    "print(f\"Area Under ROC Curve (AUC): {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T16:07:23.434698Z",
     "iopub.status.busy": "2025-04-09T16:07:23.434355Z",
     "iopub.status.idle": "2025-04-09T16:07:24.375018Z",
     "shell.execute_reply": "2025-04-09T16:07:24.374381Z",
     "shell.execute_reply.started": "2025-04-09T16:07:23.434662Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Cleaning Up ---\n",
      "--- Stopping Spark Session ---\n"
     ]
    }
   ],
   "source": [
    "# 11. Clean up\n",
    "print(\"\\n--- Cleaning Up ---\")\n",
    "train_rdd.unpersist()\n",
    "test_rdd.unpersist()\n",
    "bc_min_features.unpersist()\n",
    "bc_max_features.unpersist()\n",
    "bc_feature_ranges.unpersist()\n",
    "bc_class_weights.unpersist()\n",
    "\n",
    "# Stop Spark session\n",
    "print(\"--- Stopping Spark Session ---\")\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 44258,
     "sourceId": 6960,
     "sourceType": "competition"
    },
    {
     "datasetId": 310,
     "sourceId": 23498,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
