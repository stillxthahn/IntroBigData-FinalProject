{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6960,"databundleVersionId":44258,"sourceType":"competition"},{"sourceId":23498,"sourceType":"datasetVersion","datasetId":310}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pyspark\nfrom pyspark.sql import SparkSession\nimport math\nimport time\n\n# Create a SparkSession\nspark = SparkSession.builder \\\n    .appName(\"CreditCardFraud_LowLevel\") \\\n    .config(\"spark.driver.memory\", \"4g\") \\\n    .getOrCreate()\n\nsc = spark.sparkContext","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T13:43:07.407333Z","iopub.execute_input":"2025-04-11T13:43:07.407665Z","iopub.status.idle":"2025-04-11T13:43:15.380692Z","shell.execute_reply.started":"2025-04-11T13:43:07.407621Z","shell.execute_reply":"2025-04-11T13:43:15.379387Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"## Data Loading\nWe load the credit card fraud dataset into an RDD using low-level Spark operations:\n- Read the CSV file directly with `textFile`.\n- Filter out the header row to process only data rows.\n- Print the total number of records for verification.","metadata":{}},{"cell_type":"code","source":"# Path to the credit card dataset in Kaggle\ncredit_card_path = \"/kaggle/input/creditcardfraud/creditcard.csv\"\n\n# Load the CSV file as a text file and filter out the header\nlines_rdd = sc.textFile(credit_card_path)\nheader = lines_rdd.first()\ndata_rdd_raw = lines_rdd.filter(lambda line: line != header)\n\n# Quick count of the raw data\nprint(f\"Total number of records: {data_rdd_raw.count()}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T13:43:15.381967Z","iopub.execute_input":"2025-04-11T13:43:15.382663Z","iopub.status.idle":"2025-04-11T13:43:20.377959Z","shell.execute_reply.started":"2025-04-11T13:43:15.382619Z","shell.execute_reply":"2025-04-11T13:43:20.376889Z"}},"outputs":[{"name":"stdout","text":"Total number of records: 284807\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"## Data Parsing and Initial Analysis\nWe parse the raw text data into features and labels, and analyze the dataset:\n- Convert each line into a tuple of (features, label).\n- Cache the parsed RDD for efficiency.\n- Analyze class distribution to understand the dataset's imbalance (fraud vs. non-fraud).\n- Print the total valid records, number of features, class distribution, and a sample record.","metadata":{}},{"cell_type":"code","source":"# Parse each line into features and label\ndef parse_line(line):\n    try:\n        parts = [float(x.strip().replace('\"', '')) for x in line.split(\",\")]\n        features = parts[:-1]  # All columns except the last one\n        label = parts[-1]      # Last column is the label (Class)\n        return (features, label)\n    except Exception as e:\n        return None\n\nparsed_data_rdd = data_rdd_raw.map(parse_line).filter(lambda x: x is not None).cache()\nnum_features = len(parsed_data_rdd.first()[0])\ntotal_count = parsed_data_rdd.count()\n\nprint(f\"Total valid records: {total_count}\")\nprint(f\"Number of features: {num_features}\")\n\n# Check class distribution (important for imbalanced dataset)\nclass_counts = parsed_data_rdd.map(lambda x: (x[1], 1)).reduceByKey(lambda a, b: a + b).collectAsMap()\nprint(f\"Class distribution: {class_counts}\")\nprint(f\"Percentage of fraudulent transactions: {class_counts.get(1.0, 0)/total_count*100:.4f}%\")\n\n# Show a sample record\nprint(\"\\nSample record (features, label):\")\nprint(parsed_data_rdd.first())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T13:43:20.379009Z","iopub.execute_input":"2025-04-11T13:43:20.379303Z","iopub.status.idle":"2025-04-11T13:43:27.681214Z","shell.execute_reply.started":"2025-04-11T13:43:20.379278Z","shell.execute_reply":"2025-04-11T13:43:27.680187Z"}},"outputs":[{"name":"stdout","text":"Total valid records: 284807\nNumber of features: 30\nClass distribution: {0.0: 284315, 1.0: 492}\nPercentage of fraudulent transactions: 0.1727%\n\nSample record (features, label):\n([0.0, -1.3598071336738, -0.0727811733098497, 2.53634673796914, 1.37815522427443, -0.338320769942518, 0.462387777762292, 0.239598554061257, 0.0986979012610507, 0.363786969611213, 0.0907941719789316, -0.551599533260813, -0.617800855762348, -0.991389847235408, -0.311169353699879, 1.46817697209427, -0.470400525259478, 0.207971241929242, 0.0257905801985591, 0.403992960255733, 0.251412098239705, -0.018306777944153, 0.277837575558899, -0.110473910188767, 0.0669280749146731, 0.128539358273528, -0.189114843888824, 0.133558376740387, -0.0210530534538215, 149.62], 0.0)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"## Feature Scaling\nWe apply min-max normalization to scale features to the [0,1] range for faster convergence:\n- Compute min and max for each feature using RDD operations.\n- Broadcast min/max values to all worker nodes for efficiency.\n- Normalize features and cache the scaled RDD.\n- Print a sample scaled record and unpersist the unscaled data.","metadata":{}},{"cell_type":"code","source":"# Collect min and max for each feature using mapPartitions for better performance\ndef compute_min_max(iterator):\n    local_min_max = ([float('inf')] * num_features, [float('-inf')] * num_features)\n    for record in iterator:\n        features = record[0]\n        for i in range(num_features):\n            local_min_max[0][i] = min(local_min_max[0][i], features[i])\n            local_min_max[1][i] = max(local_min_max[1][i], features[i])\n    yield local_min_max\n\n# Aggregate min/max across all partitions\nmin_max_stats = parsed_data_rdd.mapPartitions(compute_min_max).reduce(\n    lambda x, y: (\n        [min(x[0][i], y[0][i]) for i in range(num_features)],\n        [max(x[1][i], y[1][i]) for i in range(num_features)]\n    )\n)\n\nmin_features = min_max_stats[0]\nmax_features = min_max_stats[1]\n\n# Calculate feature ranges, ensuring no division by zero\nepsilon = 1e-8  # Small value to prevent division by zero\nfeature_ranges = []\nfor i in range(num_features):\n    range_val = max_features[i] - min_features[i]\n    feature_ranges.append(max(range_val, epsilon))\n\n# Broadcast min, max, and ranges to all worker nodes\nbc_min_features = sc.broadcast(min_features)\nbc_max_features = sc.broadcast(max_features)\nbc_feature_ranges = sc.broadcast(feature_ranges)\n\n# Scale the features using min-max normalization\ndef scale_record(record):\n    features, label = record\n    scaled_features = []\n    for i in range(len(features)):\n        scaled_val = (features[i] - bc_min_features.value[i]) / bc_feature_ranges.value[i]\n        scaled_features.append(scaled_val)\n    return (scaled_features, label)\n\nscaled_data_rdd = parsed_data_rdd.map(scale_record).cache()\n\nprint(\"Sample Scaled Record (Features, Label):\")\nprint(scaled_data_rdd.first())\n\n# Unpersist the unscaled data\nparsed_data_rdd.unpersist()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T13:43:27.683368Z","iopub.execute_input":"2025-04-11T13:43:27.683723Z","iopub.status.idle":"2025-04-11T13:43:33.361331Z","shell.execute_reply.started":"2025-04-11T13:43:27.683690Z","shell.execute_reply":"2025-04-11T13:43:33.360337Z"}},"outputs":[{"name":"stdout","text":"Sample Scaled Record (Features, Label):\n([0.0, 0.9351923374337303, 0.7664904186403037, 0.8813649032863348, 0.31302265906669463, 0.7634387348529242, 0.2676686424971201, 0.26681517599177856, 0.7864441979341067, 0.4753117341039581, 0.5106004821833838, 0.25248431906394647, 0.6809076254567205, 0.3715906024604766, 0.6355905300192973, 0.4460836956482719, 0.4343923913601106, 0.7371725526870235, 0.6550658609829579, 0.5948632283047696, 0.5829422304973765, 0.5611843885604425, 0.5229921162596571, 0.6637929753279846, 0.3912526763768729, 0.5851217945036548, 0.39455679156287454, 0.4189761351972912, 0.3126966335786978, 0.0058237930868049554], 0.0)\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"PythonRDD[4] at RDD at PythonRDD.scala:53"},"metadata":{}}],"execution_count":4},{"cell_type":"markdown","source":"## Train-Test Split and Class Weighting\nWe prepare the data for training by:\n- Splitting the scaled data into training (80%) and test (20%) sets with a fixed seed for reproducibility.\n- Caching the split RDDs for efficiency.\n- Calculating class weights to handle imbalance (higher weight for the minority class, fraud).\n- Broadcasting class weights to all worker nodes.\n- Printing the sizes of the split sets and class weights.","metadata":{}},{"cell_type":"code","source":"# Randomly split data into training (80%) and testing (20%) sets\ntrain_rdd, test_rdd = scaled_data_rdd.randomSplit([0.8, 0.2], seed=42)\ntrain_rdd.cache()\ntest_rdd.cache()\n\ntrain_count = train_rdd.count()\ntest_count = test_rdd.count()\nprint(f\"Training set size: {train_count}\")\nprint(f\"Test set size: {test_count}\")\n\n# Unpersist the full scaled data RDD\nscaled_data_rdd.unpersist()\n\n# Calculate class weights on the training data\ntrain_class_counts = train_rdd.map(lambda x: (x[1], 1)).reduceByKey(lambda a, b: a + b).collectAsMap()\ncount_class_0 = train_class_counts.get(0.0, 0)\ncount_class_1 = train_class_counts.get(1.0, 0)\n\n# Compute weights: larger weight for the minority class\ntotal = count_class_0 + count_class_1\nif count_class_0 == 0 or count_class_1 == 0:\n    print(\"Warning: One class is missing in the training set. Using equal weights.\")\n    class_weights = {0.0: 1.0, 1.0: 1.0}\nelse:\n    # Simple inverse frequency weighting\n    class_weights = {\n        0.0: total / (2.0 * count_class_0),\n        1.0: total / (2.0 * count_class_1)\n    }\n\nprint(f\"Class distribution in training set - 0: {count_class_0}, 1: {count_class_1}\")\nprint(f\"Class weights - 0: {class_weights[0.0]:.4f}, 1: {class_weights[1.0]:.4f}\")\n\n# Broadcast class weights to all worker nodes\nbc_class_weights = sc.broadcast(class_weights)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T13:43:33.366020Z","iopub.execute_input":"2025-04-11T13:43:33.366402Z","iopub.status.idle":"2025-04-11T13:43:44.052430Z","shell.execute_reply.started":"2025-04-11T13:43:33.366366Z","shell.execute_reply":"2025-04-11T13:43:44.051289Z"}},"outputs":[{"name":"stdout","text":"Training set size: 228163\nTest set size: 56644\nClass distribution in training set - 0: 227769, 1: 394\nClass weights - 0: 0.5009, 1: 289.5470\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"## Logistic Regression Helper Functions\nWe define core functions for logistic regression:\n- `sigmoid`: Computes the sigmoid function with overflow protection.\n- `dot_product`: Calculates the dot product of two vectors.\n- `predict`: Predicts probabilities using weights and sigmoid.\n- `compute_gradient_and_loss`: Computes the gradient and loss for a single record, including L2 regularization and class weighting.\nThese functions are essential for the gradient descent implementation.","metadata":{}},{"cell_type":"code","source":"def sigmoid(z):\n    \"\"\"Sigmoid function with simple overflow protection\"\"\"\n    if z < -500:\n        return 0.0\n    elif z > 500:\n        return 1.0\n    else:\n        return 1.0 / (1.0 + math.exp(-z))\n\ndef dot_product(vec1, vec2):\n    \"\"\"Compute dot product of two vectors (lists)\"\"\"\n    return sum(v1 * v2 for v1, v2 in zip(vec1, vec2))\n\ndef predict(features, weights):\n    \"\"\"Predict probability using dot product and sigmoid\"\"\"\n    # Add a 1.0 for the bias term\n    features_with_bias = [1.0] + features\n    z = dot_product(features_with_bias, weights)\n    return sigmoid(z)\n\ndef compute_gradient_and_loss(record, weights, reg_param):\n    \"\"\"Compute gradient and loss for a single record with regularization\"\"\"\n    features, label = record\n    features_with_bias = [1.0] + features  # Add bias term\n    \n    # Compute prediction\n    prediction = predict(features, weights)\n    \n    # Get the weight for this class\n    class_weight = bc_class_weights.value.get(label, 1.0)\n    \n    # Compute error\n    error = prediction - label\n    \n    # Compute gradient for each feature\n    gradient = [class_weight * error * x for x in features_with_bias]\n    \n    # Add L2 regularization to all weights except bias\n    for i in range(1, len(weights)):\n        gradient[i] += reg_param * weights[i]\n    \n    # Compute log loss with epsilon to avoid log(0)\n    epsilon = 1e-9\n    if label == 1.0:\n        loss = -class_weight * math.log(prediction + epsilon)\n    else:\n        loss = -class_weight * math.log(1 - prediction + epsilon)\n        \n    # Add L2 regularization term to loss (exclude bias term)\n    reg_loss = 0.0\n    for i in range(1, len(weights)):\n        reg_loss += 0.5 * reg_param * (weights[i] ** 2)\n        \n    return (gradient, loss + reg_loss)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T13:43:44.053716Z","iopub.execute_input":"2025-04-11T13:43:44.054079Z","iopub.status.idle":"2025-04-11T13:43:44.063335Z","shell.execute_reply.started":"2025-04-11T13:43:44.054041Z","shell.execute_reply":"2025-04-11T13:43:44.062244Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"## Gradient Descent Implementation with Hyperparameter Tuning\nThis section implements the gradient descent algorithm from scratch for logistic regression and enhances it with hyperparameter tuning to optimize performance. We initialize weights (including bias term) to zeros and use L2 regularization to prevent overfitting. A grid search tests combinations of learning rates (0.01, 0.1, 0.5) and regularization parameters (0.001, 0.01, 0.1), training each model with early stopping based on a convergence threshold. Models are evaluated on the test set using AUC, suitable for the imbalanced dataset, and the best model (highest AUC) is selected. The best model's weights and performance are reported for further evaluation.","metadata":{}},{"cell_type":"code","source":"from itertools import product\nimport time\nimport math\n\n# Initialize weights (including bias term)\nnum_features_with_bias = num_features + 1  # Add 1 for bias term\ninitial_weights = [0.0] * num_features_with_bias\n\n# Define hyperparameter grid\nlearning_rates = [0.01, 0.1, 0.5]\nreg_params = [0.001, 0.01, 0.1]\nmax_iterations = 30\ntolerance = 1e-4  # Convergence threshold\n\n# Function to compute AUC (reusing from Cell 11 for validation)\ndef calculate_auc_approximation(data_rdd, weights):\n    def get_prediction_score(record):\n        features, actual_label = record\n        prob = predict(features, weights)\n        return (prob, actual_label)\n    \n    pred_scores = data_rdd.map(get_prediction_score).collect()\n    pred_scores.sort(key=lambda x: x[0], reverse=True)\n    \n    num_positive = sum(1 for _, label in pred_scores if label == 1.0)\n    num_negative = len(pred_scores) - num_positive\n    \n    if num_positive == 0 or num_negative == 0:\n        return 0.0\n    \n    auc = 0.0\n    tp = 0\n    fp = 0\n    prev_fp = 0\n    prev_tp = 0\n    \n    for prob, label in pred_scores:\n        if label == 1.0:\n            tp += 1\n        else:\n            fp += 1\n        if fp > prev_fp:\n            auc += (tp + prev_tp) * (fp - prev_fp) / (2.0 * num_positive * num_negative)\n            prev_fp = fp\n            prev_tp = tp\n    \n    return auc\n\n# Gradient descent function (extracted for reuse)\ndef run_gradient_descent(train_rdd, initial_weights, learning_rate, reg_param, max_iterations, tolerance):\n    current_weights = initial_weights.copy()\n    previous_loss = float('inf')\n    iteration_stats = []\n    \n    for iteration in range(max_iterations):\n        start_time = time.time()\n        \n        def process_partition(iterator):\n            local_gradients = [0.0] * num_features_with_bias\n            local_loss = 0.0\n            local_count = 0\n            \n            for record in iterator:\n                grad, loss = compute_gradient_and_loss(record, current_weights, reg_param)\n                local_gradients = [local_gradients[i] + grad[i] for i in range(num_features_with_bias)]\n                local_loss += loss\n                local_count += 1\n            \n            yield (local_gradients, local_loss, local_count)\n        \n        result = train_rdd.mapPartitions(process_partition).reduce(\n            lambda x, y: (\n                [x[0][i] + y[0][i] for i in range(num_features_with_bias)],\n                x[1] + y[1],\n                x[2] + y[2]\n            )\n        )\n        \n        total_gradients, total_loss, count = result\n        avg_gradients = [g / count for g in total_gradients]\n        avg_loss = total_loss / count\n        \n        for i in range(num_features_with_bias):\n            current_weights[i] -= learning_rate * avg_gradients[i]\n        \n        elapsed_time = time.time() - start_time\n        loss_change = abs(avg_loss - previous_loss)\n        iteration_stats.append((iteration+1, avg_loss, loss_change, elapsed_time))\n        \n        if (iteration+1) % 5 == 0 or iteration == 0 or iteration == max_iterations-1:\n            print(f\"Iteration {iteration+1}/{max_iterations} | Loss: {avg_loss:.6f} | Change: {loss_change:.6f} | Time: {elapsed_time:.2f}s\")\n        \n        if loss_change < tolerance:\n            print(f\"Converged at iteration {iteration+1}. Loss change below tolerance ({tolerance}).\")\n            break\n        \n        previous_loss = avg_loss\n    \n    return current_weights, iteration_stats\n\n# Hyperparameter tuning loop\nprint(\"\\nStarting Logistic Regression with Hyperparameter Tuning...\")\nbest_auc = 0.0\nbest_weights = None\nbest_params = None\nbest_stats = None\n\nfor lr, reg in product(learning_rates, reg_params):\n    print(f\"\\nTesting learning_rate={lr}, reg_param={reg}\")\n    weights, stats = run_gradient_descent(train_rdd, initial_weights, lr, reg, max_iterations, tolerance)\n    \n    # Evaluate on test set (used as validation here)\n    auc = calculate_auc_approximation(test_rdd, weights)\n    print(f\"AUC on test set: {auc:.4f}\")\n    \n    if auc > best_auc:\n        best_auc = auc\n        best_weights = weights\n        best_params = (lr, reg)\n        best_stats = stats\n\n# Report best model\nprint(\"\\n--- Best Model ---\")\nprint(f\"Best learning_rate: {best_params[0]}, reg_param: {best_params[1]}\")\nprint(f\"Best AUC: {best_auc:.4f}\")\nprint(f\"Final Weights: {best_weights}\")\n\n# Use best weights for subsequent evaluation\ncurrent_weights = best_weights","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T13:43:44.064571Z","iopub.execute_input":"2025-04-11T13:43:44.064931Z","iopub.status.idle":"2025-04-11T13:58:50.009468Z","shell.execute_reply.started":"2025-04-11T13:43:44.064895Z","shell.execute_reply":"2025-04-11T13:58:50.008337Z"}},"outputs":[{"name":"stdout","text":"\nStarting Logistic Regression with Hyperparameter Tuning...\n\nTesting learning_rate=0.01, reg_param=0.001\nIteration 1/30 | Loss: 0.693147 | Change: inf | Time: 3.22s\nIteration 5/30 | Loss: 0.692325 | Change: 0.000204 | Time: 3.27s\nIteration 10/30 | Loss: 0.691323 | Change: 0.000198 | Time: 3.34s\nIteration 15/30 | Loss: 0.690347 | Change: 0.000194 | Time: 3.27s\nIteration 20/30 | Loss: 0.689390 | Change: 0.000190 | Time: 3.33s\nIteration 25/30 | Loss: 0.688450 | Change: 0.000187 | Time: 3.26s\nIteration 30/30 | Loss: 0.687524 | Change: 0.000184 | Time: 3.24s\nAUC on test set: 0.9593\n\nTesting learning_rate=0.01, reg_param=0.01\nIteration 1/30 | Loss: 0.693147 | Change: inf | Time: 3.11s\nIteration 5/30 | Loss: 0.692325 | Change: 0.000204 | Time: 3.32s\nIteration 10/30 | Loss: 0.691325 | Change: 0.000198 | Time: 3.27s\nIteration 15/30 | Loss: 0.690350 | Change: 0.000193 | Time: 3.27s\nIteration 20/30 | Loss: 0.689397 | Change: 0.000189 | Time: 3.33s\nIteration 25/30 | Loss: 0.688460 | Change: 0.000186 | Time: 3.35s\nIteration 30/30 | Loss: 0.687538 | Change: 0.000183 | Time: 3.27s\nAUC on test set: 0.9593\n\nTesting learning_rate=0.01, reg_param=0.1\nIteration 1/30 | Loss: 0.693147 | Change: inf | Time: 3.19s\nIteration 5/30 | Loss: 0.692327 | Change: 0.000202 | Time: 3.78s\nIteration 10/30 | Loss: 0.691339 | Change: 0.000195 | Time: 3.31s\nIteration 15/30 | Loss: 0.690384 | Change: 0.000189 | Time: 3.87s\nIteration 20/30 | Loss: 0.689457 | Change: 0.000183 | Time: 3.34s\nIteration 25/30 | Loss: 0.688556 | Change: 0.000178 | Time: 3.83s\nIteration 30/30 | Loss: 0.687676 | Change: 0.000174 | Time: 3.29s\nAUC on test set: 0.9593\n\nTesting learning_rate=0.1, reg_param=0.001\nIteration 1/30 | Loss: 0.693147 | Change: inf | Time: 3.25s\nIteration 5/30 | Loss: 0.685493 | Change: 0.001816 | Time: 3.41s\nIteration 10/30 | Loss: 0.676773 | Change: 0.001709 | Time: 3.30s\nIteration 15/30 | Loss: 0.668428 | Change: 0.001643 | Time: 3.26s\nIteration 20/30 | Loss: 0.660398 | Change: 0.001582 | Time: 3.26s\nIteration 25/30 | Loss: 0.652666 | Change: 0.001523 | Time: 3.31s\nIteration 30/30 | Loss: 0.645220 | Change: 0.001467 | Time: 3.26s\nAUC on test set: 0.9613\n\nTesting learning_rate=0.1, reg_param=0.01\nIteration 1/30 | Loss: 0.693147 | Change: inf | Time: 3.19s\nIteration 5/30 | Loss: 0.685516 | Change: 0.001805 | Time: 3.25s\nIteration 10/30 | Loss: 0.676894 | Change: 0.001684 | Time: 3.30s\nIteration 15/30 | Loss: 0.668715 | Change: 0.001605 | Time: 3.22s\nIteration 20/30 | Loss: 0.660914 | Change: 0.001531 | Time: 3.25s\nIteration 25/30 | Loss: 0.653470 | Change: 0.001461 | Time: 3.28s\nIteration 30/30 | Loss: 0.646365 | Change: 0.001395 | Time: 3.30s\nAUC on test set: 0.9613\n\nTesting learning_rate=0.1, reg_param=0.1\nIteration 1/30 | Loss: 0.693147 | Change: inf | Time: 3.24s\nIteration 5/30 | Loss: 0.685749 | Change: 0.001701 | Time: 3.24s\nIteration 10/30 | Loss: 0.678042 | Change: 0.001452 | Time: 3.30s\nIteration 15/30 | Loss: 0.671357 | Change: 0.001265 | Time: 3.27s\nIteration 20/30 | Loss: 0.665525 | Change: 0.001104 | Time: 3.24s\nIteration 25/30 | Loss: 0.660433 | Change: 0.000964 | Time: 3.30s\nIteration 30/30 | Loss: 0.655988 | Change: 0.000842 | Time: 3.25s\nAUC on test set: 0.9612\n\nTesting learning_rate=0.5, reg_param=0.001\nIteration 1/30 | Loss: 0.693147 | Change: inf | Time: 3.21s\nIteration 5/30 | Loss: 0.658587 | Change: 0.008023 | Time: 3.31s\nIteration 10/30 | Loss: 0.622732 | Change: 0.006644 | Time: 3.33s\nIteration 15/30 | Loss: 0.592910 | Change: 0.005546 | Time: 3.25s\nIteration 20/30 | Loss: 0.567871 | Change: 0.004676 | Time: 3.24s\nIteration 25/30 | Loss: 0.546623 | Change: 0.003987 | Time: 3.32s\nIteration 30/30 | Loss: 0.528391 | Change: 0.003436 | Time: 3.24s\nAUC on test set: 0.9634\n\nTesting learning_rate=0.5, reg_param=0.01\nIteration 1/30 | Loss: 0.693147 | Change: inf | Time: 3.71s\nIteration 5/30 | Loss: 0.659110 | Change: 0.007789 | Time: 3.25s\nIteration 10/30 | Loss: 0.625207 | Change: 0.006165 | Time: 3.30s\nIteration 15/30 | Loss: 0.598262 | Change: 0.004916 | Time: 3.25s\nIteration 20/30 | Loss: 0.576655 | Change: 0.003958 | Time: 3.23s\nIteration 25/30 | Loss: 0.559155 | Change: 0.003220 | Time: 3.31s\nIteration 30/30 | Loss: 0.544837 | Change: 0.002645 | Time: 3.24s\nAUC on test set: 0.9633\n\nTesting learning_rate=0.5, reg_param=0.1\nIteration 1/30 | Loss: 0.693147 | Change: inf | Time: 3.54s\nIteration 5/30 | Loss: 0.663854 | Change: 0.005758 | Time: 3.23s\nIteration 10/30 | Loss: 0.644526 | Change: 0.002875 | Time: 3.44s\nIteration 15/30 | Loss: 0.634804 | Change: 0.001456 | Time: 3.29s\nIteration 20/30 | Loss: 0.629826 | Change: 0.000754 | Time: 3.52s\nIteration 25/30 | Loss: 0.627206 | Change: 0.000403 | Time: 3.27s\nIteration 30/30 | Loss: 0.625769 | Change: 0.000226 | Time: 3.62s\nAUC on test set: 0.9629\n\n--- Best Model ---\nBest learning_rate: 0.5, reg_param: 0.001\nBest AUC: 0.9634\nFinal Weights: [0.1830546977463707, -0.11838603726253982, -0.06760194509048988, 0.2547186164844601, -0.21331068394906214, 0.6676496237797149, 0.08065942330145387, 0.005440992639919822, -0.05169140970521707, 0.1449051821912893, -0.18053865444315423, -0.25758781397996355, 0.7318980710463681, -0.5750758893456556, 0.02986779604802562, -0.606852961305054, 0.04199920957631534, -0.2994060613135832, -0.4172048873115122, -0.3098363745085256, 0.23411041976200142, 0.11827687000366927, 0.14104265342144523, 0.08570475531651121, 0.1180203798421748, 0.018264136869969992, 0.1156888592944205, 0.09044294881313987, 0.0860869721085755, 0.06326309300306056, 0.005912445908994038]\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"## Model Evaluation\nWe evaluate the model on the test set using a threshold of 0.5:\n- Compute the confusion matrix (TP, FP, TN, FN).\n- Calculate accuracy, precision, recall, and F1-score.\n- Print the results, focusing on recall (sensitivity) as it's critical for fraud detection.","metadata":{}},{"cell_type":"code","source":"def evaluate_model(test_data, weights, threshold=0.5):\n    \"\"\"Evaluate the model on test data\"\"\"\n    # Function to predict and compare with actual label\n    def predict_and_evaluate(record):\n        features, actual_label = record\n        prob = predict(features, weights)\n        predicted_label = 1.0 if prob >= threshold else 0.0\n        return (predicted_label, actual_label, prob)\n    \n    # Get predictions for all test records\n    predictions = test_data.map(predict_and_evaluate)\n    predictions.cache()\n    \n    # Calculate confusion matrix counts\n    tp = predictions.filter(lambda x: x[0] == 1.0 and x[1] == 1.0).count()\n    fp = predictions.filter(lambda x: x[0] == 1.0 and x[1] == 0.0).count()\n    tn = predictions.filter(lambda x: x[0] == 0.0 and x[1] == 0.0).count()\n    fn = predictions.filter(lambda x: x[0] == 0.0 and x[1] == 1.0).count()\n    \n    # Calculate metrics\n    total = tp + tn + fp + fn\n    accuracy = (tp + tn) / total if total > 0 else 0\n    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n    \n    # Unpersist predictions RDD\n    predictions.unpersist()\n    \n    return {\n        \"accuracy\": accuracy,\n        \"precision\": precision,\n        \"recall\": recall,\n        \"f1_score\": f1,\n        \"confusion_matrix\": {\"tp\": tp, \"fp\": fp, \"tn\": tn, \"fn\": fn}\n    }\n\n# Evaluate model with default threshold of 0.5\nprint(\"\\n--- Evaluating Model on Test Set ---\")\nevaluation = evaluate_model(test_rdd, current_weights, threshold=0.5)\n\nprint(\"Results with threshold=0.5:\")\nprint(f\"Accuracy:  {evaluation['accuracy']:.4f}\")\nprint(f\"Precision: {evaluation['precision']:.4f}\")\nprint(f\"Recall:    {evaluation['recall']:.4f} (Sensitivity)\")\nprint(f\"F1-Score:  {evaluation['f1_score']:.4f}\")\nprint(\"Confusion Matrix:\")\nprint(f\"  True Positives:  {evaluation['confusion_matrix']['tp']}\")\nprint(f\"  False Positives: {evaluation['confusion_matrix']['fp']}\")\nprint(f\"  True Negatives:  {evaluation['confusion_matrix']['tn']}\")\nprint(f\"  False Negatives: {evaluation['confusion_matrix']['fn']}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T13:58:50.010625Z","iopub.execute_input":"2025-04-11T13:58:50.010964Z","iopub.status.idle":"2025-04-11T13:58:52.206768Z","shell.execute_reply.started":"2025-04-11T13:58:50.010935Z","shell.execute_reply":"2025-04-11T13:58:52.205693Z"}},"outputs":[{"name":"stdout","text":"\n--- Evaluating Model on Test Set ---\nResults with threshold=0.5:\nAccuracy:  0.9993\nPrecision: 0.8427\nRecall:    0.7653 (Sensitivity)\nF1-Score:  0.8021\nConfusion Matrix:\n  True Positives:  75\n  False Positives: 14\n  True Negatives:  56532\n  False Negatives: 23\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"## Threshold Tuning and AUC Calculation\nWe explore model performance further:\n- Test different decision thresholds (0.1 to 0.9) to balance precision and recall, as the default 0.5 may not be optimal for imbalanced data.\n- Calculate the Area Under the ROC Curve (AUC) using an approximation with the trapezoidal rule, a key metric for imbalanced datasets.\n- Print the results for each threshold and the AUC value.","metadata":{}},{"cell_type":"code","source":"# Try different thresholds to find better precision-recall balance\nprint(\"\\n--- Evaluating Different Thresholds ---\")\nthresholds = [0.1, 0.3, 0.5, 0.7, 0.9]\nfor threshold in thresholds:\n    eval_result = evaluate_model(test_rdd, current_weights, threshold)\n    print(f\"Threshold={threshold:.1f} | Precision: {eval_result['precision']:.4f} | Recall: {eval_result['recall']:.4f} | F1: {eval_result['f1_score']:.4f}\")\n\n# Calculate AUC\ndef calculate_auc_approximation(test_data, weights):\n    \"\"\"Calculate an approximation of the AUC using discrete thresholds\"\"\"\n    # Function to get prediction probabilities and actual labels\n    def get_prediction_score(record):\n        features, actual_label = record\n        prob = predict(features, weights)\n        return (prob, actual_label)\n    \n    # Get prediction scores and sort them\n    pred_scores = test_data.map(get_prediction_score).collect()\n    pred_scores.sort(key=lambda x: x[0], reverse=True)\n    \n    # Initialize counters\n    num_positive = sum(1 for _, label in pred_scores if label == 1.0)\n    num_negative = len(pred_scores) - num_positive\n    \n    if num_positive == 0 or num_negative == 0:\n        print(\"Warning: Only one class present in test set. AUC calculation not possible.\")\n        return 0.0\n    \n    # Initialize the area\n    auc = 0.0\n    tp = 0\n    fp = 0\n    prev_fp = 0\n    prev_tp = 0\n    \n    # Process each prediction\n    for prob, label in pred_scores:\n        if label == 1.0:\n            tp += 1\n        else:\n            fp += 1\n            \n        # Add trapezoid area under the curve\n        if fp > prev_fp:\n            auc += (tp + prev_tp) * (fp - prev_fp) / (2.0 * num_positive * num_negative)\n            prev_fp = fp\n            prev_tp = tp\n    \n    return auc\n\nprint(\"\\n--- AUC Approximation ---\")\nauc = calculate_auc_approximation(test_rdd, current_weights)\nprint(f\"Area Under ROC Curve (AUC): {auc:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T13:58:52.207771Z","iopub.execute_input":"2025-04-11T13:58:52.208127Z","iopub.status.idle":"2025-04-11T13:59:03.785552Z","shell.execute_reply.started":"2025-04-11T13:58:52.208100Z","shell.execute_reply":"2025-04-11T13:59:03.784516Z"}},"outputs":[{"name":"stdout","text":"\n--- Evaluating Different Thresholds ---\nThreshold=0.1 | Precision: 0.0017 | Recall: 1.0000 | F1: 0.0035\nThreshold=0.3 | Precision: 0.0017 | Recall: 1.0000 | F1: 0.0035\nThreshold=0.5 | Precision: 0.8427 | Recall: 0.7653 | F1: 0.8021\nThreshold=0.7 | Precision: 0.8571 | Recall: 0.2449 | F1: 0.3810\nThreshold=0.9 | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000\n\n--- AUC Approximation ---\nArea Under ROC Curve (AUC): 0.9634\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"## Cleanup and Shutdown\nWe clean up resources to free memory and stop the Spark session:\n- Unpersist cached RDDs (`train_rdd`, `test_rdd`).\n- Unpersist broadcast variables.\n- Stop the Spark session to ensure proper shutdown.","metadata":{}},{"cell_type":"code","source":"# Clean up\n\ntrain_rdd.unpersist()\ntest_rdd.unpersist()\nbc_min_features.unpersist()\nbc_max_features.unpersist()\nbc_feature_ranges.unpersist()\nbc_class_weights.unpersist()\n\n# Stop Spark session\nprint(\"--- Stopping Spark Session ---\")\nspark.stop()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T13:59:03.786569Z","iopub.execute_input":"2025-04-11T13:59:03.786859Z","iopub.status.idle":"2025-04-11T13:59:04.697285Z","shell.execute_reply.started":"2025-04-11T13:59:03.786833Z","shell.execute_reply":"2025-04-11T13:59:04.696225Z"}},"outputs":[{"name":"stdout","text":"--- Stopping Spark Session ---\n","output_type":"stream"}],"execution_count":10}]}