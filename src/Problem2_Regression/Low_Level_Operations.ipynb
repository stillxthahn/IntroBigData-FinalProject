{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6960,"databundleVersionId":44258,"sourceType":"competition"},{"sourceId":23498,"sourceType":"datasetVersion","datasetId":310}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pyspark\nfrom pyspark.sql import SparkSession\nimport math\nimport time\n\n# Create a SparkSession\nspark = SparkSession.builder \\\n    .appName(\"CreditCardFraud_LowLevel\") \\\n    .config(\"spark.driver.memory\", \"4g\") \\\n    .getOrCreate()\n\nsc = spark.sparkContext","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T07:33:46.698051Z","iopub.execute_input":"2025-04-11T07:33:46.698437Z","iopub.status.idle":"2025-04-11T07:33:46.806429Z","shell.execute_reply.started":"2025-04-11T07:33:46.698411Z","shell.execute_reply":"2025-04-11T07:33:46.805484Z"}},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":"## Data Loading\nWe load the credit card fraud dataset into an RDD using low-level Spark operations:\n- Read the CSV file directly with `textFile`.\n- Filter out the header row to process only data rows.\n- Print the total number of records for verification.","metadata":{}},{"cell_type":"code","source":"# Path to the credit card dataset in Kaggle\ncredit_card_path = \"/kaggle/input/creditcardfraud/creditcard.csv\"\n\n# Load the CSV file as a text file and filter out the header\nlines_rdd = sc.textFile(credit_card_path)\nheader = lines_rdd.first()\ndata_rdd_raw = lines_rdd.filter(lambda line: line != header)\n\n# Quick count of the raw data\nprint(f\"Total number of records: {data_rdd_raw.count()}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T07:33:46.807592Z","iopub.execute_input":"2025-04-11T07:33:46.807883Z","iopub.status.idle":"2025-04-11T07:33:48.471564Z","shell.execute_reply.started":"2025-04-11T07:33:46.807854Z","shell.execute_reply":"2025-04-11T07:33:48.470695Z"}},"outputs":[{"name":"stdout","text":"Total number of records: 284807\n","output_type":"stream"}],"execution_count":22},{"cell_type":"markdown","source":"## Data Parsing and Initial Analysis\nWe parse the raw text data into features and labels, and analyze the dataset:\n- Convert each line into a tuple of (features, label).\n- Cache the parsed RDD for efficiency.\n- Analyze class distribution to understand the dataset's imbalance (fraud vs. non-fraud).\n- Print the total valid records, number of features, class distribution, and a sample record.","metadata":{}},{"cell_type":"code","source":"# Parse each line into features and label\ndef parse_line(line):\n    try:\n        parts = [float(x.strip().replace('\"', '')) for x in line.split(\",\")]\n        features = parts[:-1]  # All columns except the last one\n        label = parts[-1]      # Last column is the label (Class)\n        return (features, label)\n    except Exception as e:\n        return None\n\nparsed_data_rdd = data_rdd_raw.map(parse_line).filter(lambda x: x is not None).cache()\nnum_features = len(parsed_data_rdd.first()[0])\ntotal_count = parsed_data_rdd.count()\n\nprint(f\"Total valid records: {total_count}\")\nprint(f\"Number of features: {num_features}\")\n\n# Check class distribution (important for imbalanced dataset)\nclass_counts = parsed_data_rdd.map(lambda x: (x[1], 1)).reduceByKey(lambda a, b: a + b).collectAsMap()\nprint(f\"Class distribution: {class_counts}\")\nprint(f\"Percentage of fraudulent transactions: {class_counts.get(1.0, 0)/total_count*100:.4f}%\")\n\n# Show a sample record\nprint(\"\\nSample record (features, label):\")\nprint(parsed_data_rdd.first())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T07:33:48.473034Z","iopub.execute_input":"2025-04-11T07:33:48.473307Z","iopub.status.idle":"2025-04-11T07:33:53.434773Z","shell.execute_reply.started":"2025-04-11T07:33:48.473284Z","shell.execute_reply":"2025-04-11T07:33:53.433816Z"}},"outputs":[{"name":"stdout","text":"Total valid records: 284807\nNumber of features: 30\nClass distribution: {0.0: 284315, 1.0: 492}\nPercentage of fraudulent transactions: 0.1727%\n\nSample record (features, label):\n([0.0, -1.3598071336738, -0.0727811733098497, 2.53634673796914, 1.37815522427443, -0.338320769942518, 0.462387777762292, 0.239598554061257, 0.0986979012610507, 0.363786969611213, 0.0907941719789316, -0.551599533260813, -0.617800855762348, -0.991389847235408, -0.311169353699879, 1.46817697209427, -0.470400525259478, 0.207971241929242, 0.0257905801985591, 0.403992960255733, 0.251412098239705, -0.018306777944153, 0.277837575558899, -0.110473910188767, 0.0669280749146731, 0.128539358273528, -0.189114843888824, 0.133558376740387, -0.0210530534538215, 149.62], 0.0)\n","output_type":"stream"}],"execution_count":23},{"cell_type":"markdown","source":"## Feature Scaling\nWe apply min-max normalization to scale features to the [0,1] range for faster convergence:\n- Compute min and max for each feature using RDD operations.\n- Broadcast min/max values to all worker nodes for efficiency.\n- Normalize features and cache the scaled RDD.\n- Print a sample scaled record and unpersist the unscaled data.","metadata":{}},{"cell_type":"code","source":"# Collect min and max for each feature using mapPartitions for better performance\ndef compute_min_max(iterator):\n    local_min_max = ([float('inf')] * num_features, [float('-inf')] * num_features)\n    for record in iterator:\n        features = record[0]\n        for i in range(num_features):\n            local_min_max[0][i] = min(local_min_max[0][i], features[i])\n            local_min_max[1][i] = max(local_min_max[1][i], features[i])\n    yield local_min_max\n\n# Aggregate min/max across all partitions\nmin_max_stats = parsed_data_rdd.mapPartitions(compute_min_max).reduce(\n    lambda x, y: (\n        [min(x[0][i], y[0][i]) for i in range(num_features)],\n        [max(x[1][i], y[1][i]) for i in range(num_features)]\n    )\n)\n\nmin_features = min_max_stats[0]\nmax_features = min_max_stats[1]\n\n# Calculate feature ranges, ensuring no division by zero\nepsilon = 1e-8  # Small value to prevent division by zero\nfeature_ranges = []\nfor i in range(num_features):\n    range_val = max_features[i] - min_features[i]\n    feature_ranges.append(max(range_val, epsilon))\n\n# Broadcast min, max, and ranges to all worker nodes\nbc_min_features = sc.broadcast(min_features)\nbc_max_features = sc.broadcast(max_features)\nbc_feature_ranges = sc.broadcast(feature_ranges)\n\n# Scale the features using min-max normalization\ndef scale_record(record):\n    features, label = record\n    scaled_features = []\n    for i in range(len(features)):\n        scaled_val = (features[i] - bc_min_features.value[i]) / bc_feature_ranges.value[i]\n        scaled_features.append(scaled_val)\n    return (scaled_features, label)\n\nscaled_data_rdd = parsed_data_rdd.map(scale_record).cache()\n\nprint(\"Sample Scaled Record (Features, Label):\")\nprint(scaled_data_rdd.first())\n\n# Unpersist the unscaled data\nparsed_data_rdd.unpersist()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T07:33:53.436454Z","iopub.execute_input":"2025-04-11T07:33:53.436867Z","iopub.status.idle":"2025-04-11T07:33:57.711896Z","shell.execute_reply.started":"2025-04-11T07:33:53.436830Z","shell.execute_reply":"2025-04-11T07:33:57.710974Z"}},"outputs":[{"name":"stdout","text":"Sample Scaled Record (Features, Label):\n([0.0, 0.9351923374337303, 0.7664904186403037, 0.8813649032863348, 0.31302265906669463, 0.7634387348529242, 0.2676686424971201, 0.26681517599177856, 0.7864441979341067, 0.4753117341039581, 0.5106004821833838, 0.25248431906394647, 0.6809076254567205, 0.3715906024604766, 0.6355905300192973, 0.4460836956482719, 0.4343923913601106, 0.7371725526870235, 0.6550658609829579, 0.5948632283047696, 0.5829422304973765, 0.5611843885604425, 0.5229921162596571, 0.6637929753279846, 0.3912526763768729, 0.5851217945036548, 0.39455679156287454, 0.4189761351972912, 0.3126966335786978, 0.0058237930868049554], 0.0)\n","output_type":"stream"},{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"PythonRDD[4] at RDD at PythonRDD.scala:53"},"metadata":{}}],"execution_count":24},{"cell_type":"markdown","source":"## Train-Test Split and Class Weighting\nWe prepare the data for training by:\n- Splitting the scaled data into training (80%) and test (20%) sets with a fixed seed for reproducibility.\n- Caching the split RDDs for efficiency.\n- Calculating class weights to handle imbalance (higher weight for the minority class, fraud).\n- Broadcasting class weights to all worker nodes.\n- Printing the sizes of the split sets and class weights.","metadata":{}},{"cell_type":"code","source":"# Randomly split data into training (80%) and testing (20%) sets\ntrain_rdd, test_rdd = scaled_data_rdd.randomSplit([0.8, 0.2], seed=42)\ntrain_rdd.cache()\ntest_rdd.cache()\n\ntrain_count = train_rdd.count()\ntest_count = test_rdd.count()\nprint(f\"Training set size: {train_count}\")\nprint(f\"Test set size: {test_count}\")\n\n# Unpersist the full scaled data RDD\nscaled_data_rdd.unpersist()\n\n# Calculate class weights on the training data\ntrain_class_counts = train_rdd.map(lambda x: (x[1], 1)).reduceByKey(lambda a, b: a + b).collectAsMap()\ncount_class_0 = train_class_counts.get(0.0, 0)\ncount_class_1 = train_class_counts.get(1.0, 0)\n\n# Compute weights: larger weight for the minority class\ntotal = count_class_0 + count_class_1\nif count_class_0 == 0 or count_class_1 == 0:\n    print(\"Warning: One class is missing in the training set. Using equal weights.\")\n    class_weights = {0.0: 1.0, 1.0: 1.0}\nelse:\n    # Simple inverse frequency weighting\n    class_weights = {\n        0.0: total / (2.0 * count_class_0),\n        1.0: total / (2.0 * count_class_1)\n    }\n\nprint(f\"Class distribution in training set - 0: {count_class_0}, 1: {count_class_1}\")\nprint(f\"Class weights - 0: {class_weights[0.0]:.4f}, 1: {class_weights[1.0]:.4f}\")\n\n# Broadcast class weights to all worker nodes\nbc_class_weights = sc.broadcast(class_weights)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T07:33:57.713468Z","iopub.execute_input":"2025-04-11T07:33:57.713771Z","iopub.status.idle":"2025-04-11T07:34:04.936637Z","shell.execute_reply.started":"2025-04-11T07:33:57.713741Z","shell.execute_reply":"2025-04-11T07:34:04.935611Z"}},"outputs":[{"name":"stdout","text":"Training set size: 228163\nTest set size: 56644\nClass distribution in training set - 0: 227769, 1: 394\nClass weights - 0: 0.5009, 1: 289.5470\n","output_type":"stream"}],"execution_count":25},{"cell_type":"markdown","source":"## Logistic Regression Helper Functions\nWe define core functions for logistic regression:\n- `sigmoid`: Computes the sigmoid function with overflow protection.\n- `dot_product`: Calculates the dot product of two vectors.\n- `predict`: Predicts probabilities using weights and sigmoid.\n- `compute_gradient_and_loss`: Computes the gradient and loss for a single record, including L2 regularization and class weighting.\nThese functions are essential for the gradient descent implementation.","metadata":{}},{"cell_type":"code","source":"def sigmoid(z):\n    \"\"\"Sigmoid function with simple overflow protection\"\"\"\n    if z < -500:\n        return 0.0\n    elif z > 500:\n        return 1.0\n    else:\n        return 1.0 / (1.0 + math.exp(-z))\n\ndef dot_product(vec1, vec2):\n    \"\"\"Compute dot product of two vectors (lists)\"\"\"\n    return sum(v1 * v2 for v1, v2 in zip(vec1, vec2))\n\ndef predict(features, weights):\n    \"\"\"Predict probability using dot product and sigmoid\"\"\"\n    # Add a 1.0 for the bias term\n    features_with_bias = [1.0] + features\n    z = dot_product(features_with_bias, weights)\n    return sigmoid(z)\n\ndef compute_gradient_and_loss(record, weights, reg_param):\n    \"\"\"Compute gradient and loss for a single record with regularization\"\"\"\n    features, label = record\n    features_with_bias = [1.0] + features  # Add bias term\n    \n    # Compute prediction\n    prediction = predict(features, weights)\n    \n    # Get the weight for this class\n    class_weight = bc_class_weights.value.get(label, 1.0)\n    \n    # Compute error\n    error = prediction - label\n    \n    # Compute gradient for each feature\n    gradient = [class_weight * error * x for x in features_with_bias]\n    \n    # Add L2 regularization to all weights except bias\n    for i in range(1, len(weights)):\n        gradient[i] += reg_param * weights[i]\n    \n    # Compute log loss with epsilon to avoid log(0)\n    epsilon = 1e-9\n    if label == 1.0:\n        loss = -class_weight * math.log(prediction + epsilon)\n    else:\n        loss = -class_weight * math.log(1 - prediction + epsilon)\n        \n    # Add L2 regularization term to loss (exclude bias term)\n    reg_loss = 0.0\n    for i in range(1, len(weights)):\n        reg_loss += 0.5 * reg_param * (weights[i] ** 2)\n        \n    return (gradient, loss + reg_loss)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T07:34:04.938581Z","iopub.execute_input":"2025-04-11T07:34:04.938913Z","iopub.status.idle":"2025-04-11T07:34:04.949194Z","shell.execute_reply.started":"2025-04-11T07:34:04.938880Z","shell.execute_reply":"2025-04-11T07:34:04.948238Z"}},"outputs":[],"execution_count":26},{"cell_type":"markdown","source":"## Gradient Descent Implementation\nWe implement gradient descent to train the logistic regression model:\n- Initialize weights (including bias) to zeros.\n- Set parameters: learning rate, max iterations, L2 regularization, and convergence tolerance.\n- Iterate over the training data, computing gradients and loss per partition.\n- Update weights, check for convergence, and print progress every 5 iterations.\n- Print the final weights after training.","metadata":{}},{"cell_type":"code","source":"# Initialize weights (including bias term)\nnum_features_with_bias = num_features + 1  # Add 1 for bias term\ninitial_weights = [0.0] * num_features_with_bias\n\n# Gradient Descent Parameters\nlearning_rate = 0.1\nmax_iterations = 50\nreg_param = 0.01  # L2 regularization strength\ntolerance = 1e-4  # Convergence threshold\n\n# Training loop\ncurrent_weights = initial_weights.copy()\nprevious_loss = float('inf')\niteration_stats = []\n\nprint(f\"\\nStarting Low-Level Logistic Regression Training...\")\nprint(f\"Parameters: Learning Rate={learning_rate}, L2 Reg={reg_param}, Max Iterations={max_iterations}\")\n\nfor iteration in range(max_iterations):\n    start_time = time.time()\n    \n    # Process each partition to compute local gradients and losses\n    def process_partition(iterator):\n        local_gradients = [0.0] * num_features_with_bias\n        local_loss = 0.0\n        local_count = 0\n        \n        for record in iterator:\n            grad, loss = compute_gradient_and_loss(record, current_weights, reg_param)\n            # Add to local gradient sum\n            local_gradients = [local_gradients[i] + grad[i] for i in range(num_features_with_bias)]\n            local_loss += loss\n            local_count += 1\n            \n        yield (local_gradients, local_loss, local_count)\n    \n    # Map partitions and reduce results\n    result = train_rdd.mapPartitions(process_partition).reduce(\n        lambda x, y: (\n            [x[0][i] + y[0][i] for i in range(num_features_with_bias)],\n            x[1] + y[1],\n            x[2] + y[2]\n        )\n    )\n    \n    total_gradients, total_loss, count = result\n    \n    # Average the gradients and loss\n    avg_gradients = [g / count for g in total_gradients]\n    avg_loss = total_loss / count\n    \n    # Update weights using gradient descent\n    for i in range(num_features_with_bias):\n        current_weights[i] -= learning_rate * avg_gradients[i]\n    \n    # Compute time taken\n    elapsed_time = time.time() - start_time\n    \n    # Check for convergence\n    loss_change = abs(avg_loss - previous_loss)\n    iteration_stats.append((iteration+1, avg_loss, loss_change, elapsed_time))\n    \n    # Print progress periodically\n    if (iteration+1) % 5 == 0 or iteration == 0 or iteration == max_iterations-1:\n        print(f\"Iteration {iteration+1}/{max_iterations} | Loss: {avg_loss:.6f} | Change: {loss_change:.6f} | Time: {elapsed_time:.2f}s\")\n    \n    if loss_change < tolerance:\n        print(f\"\\nConverged at iteration {iteration+1}. Loss change below tolerance ({tolerance}).\")\n        break\n        \n    previous_loss = avg_loss\n\nprint(\"\\n--- Training Complete ---\")\nprint(f\"Final Weights: {current_weights}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T07:34:04.949965Z","iopub.execute_input":"2025-04-11T07:34:04.950260Z","iopub.status.idle":"2025-04-11T07:36:19.696812Z","shell.execute_reply.started":"2025-04-11T07:34:04.950217Z","shell.execute_reply":"2025-04-11T07:36:19.695972Z"}},"outputs":[{"name":"stdout","text":"\nStarting Low-Level Logistic Regression Training...\nParameters: Learning Rate=0.1, L2 Reg=0.01, Max Iterations=50\nIteration 1/50 | Loss: 0.693147 | Change: inf | Time: 2.59s\nIteration 5/50 | Loss: 0.685516 | Change: 0.001805 | Time: 2.97s\nIteration 10/50 | Loss: 0.676894 | Change: 0.001684 | Time: 2.63s\nIteration 15/50 | Loss: 0.668715 | Change: 0.001605 | Time: 2.71s\nIteration 20/50 | Loss: 0.660914 | Change: 0.001531 | Time: 2.70s\nIteration 25/50 | Loss: 0.653470 | Change: 0.001461 | Time: 2.63s\nIteration 30/50 | Loss: 0.646365 | Change: 0.001395 | Time: 2.69s\nIteration 35/50 | Loss: 0.639582 | Change: 0.001332 | Time: 2.64s\nIteration 40/50 | Loss: 0.633104 | Change: 0.001272 | Time: 2.64s\nIteration 45/50 | Loss: 0.626917 | Change: 0.001215 | Time: 2.70s\nIteration 50/50 | Loss: 0.621005 | Change: 0.001161 | Time: 2.67s\n\n--- Training Complete ---\nFinal Weights: [0.06734645501449467, -0.05563508104503643, -0.0307177798823093, 0.09482797381106739, -0.08483287211062569, 0.24919008090166292, 0.026775392831556895, 0.0014345193636877034, -0.021690508027758387, 0.05432674780093182, -0.07131989193870482, -0.1006687486914826, 0.276866297182347, -0.22216872292754108, 0.013743072817229559, -0.22704821196748762, 0.014692141392756949, -0.11856268681337567, -0.1683849874940209, -0.12928158452069258, 0.09112642311815115, 0.04313528380921251, 0.050759787974399215, 0.03205432088111359, 0.0428267088508199, 0.007604685718966923, 0.04174157532936403, 0.034505036118294787, 0.03110204650344868, 0.022733018365845566, 0.0019189700665831282]\n","output_type":"stream"}],"execution_count":27},{"cell_type":"markdown","source":"## Model Evaluation\nWe evaluate the model on the test set using a threshold of 0.5:\n- Compute the confusion matrix (TP, FP, TN, FN).\n- Calculate accuracy, precision, recall, and F1-score.\n- Print the results, focusing on recall (sensitivity) as it's critical for fraud detection.","metadata":{}},{"cell_type":"code","source":"def evaluate_model(test_data, weights, threshold=0.5):\n    \"\"\"Evaluate the model on test data\"\"\"\n    # Function to predict and compare with actual label\n    def predict_and_evaluate(record):\n        features, actual_label = record\n        prob = predict(features, weights)\n        predicted_label = 1.0 if prob >= threshold else 0.0\n        return (predicted_label, actual_label, prob)\n    \n    # Get predictions for all test records\n    predictions = test_data.map(predict_and_evaluate)\n    predictions.cache()\n    \n    # Calculate confusion matrix counts\n    tp = predictions.filter(lambda x: x[0] == 1.0 and x[1] == 1.0).count()\n    fp = predictions.filter(lambda x: x[0] == 1.0 and x[1] == 0.0).count()\n    tn = predictions.filter(lambda x: x[0] == 0.0 and x[1] == 0.0).count()\n    fn = predictions.filter(lambda x: x[0] == 0.0 and x[1] == 1.0).count()\n    \n    # Calculate metrics\n    total = tp + tn + fp + fn\n    accuracy = (tp + tn) / total if total > 0 else 0\n    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n    \n    # Unpersist predictions RDD\n    predictions.unpersist()\n    \n    return {\n        \"accuracy\": accuracy,\n        \"precision\": precision,\n        \"recall\": recall,\n        \"f1_score\": f1,\n        \"confusion_matrix\": {\"tp\": tp, \"fp\": fp, \"tn\": tn, \"fn\": fn}\n    }\n\n# Evaluate model with default threshold of 0.5\nprint(\"\\n--- Evaluating Model on Test Set ---\")\nevaluation = evaluate_model(test_rdd, current_weights, threshold=0.5)\n\nprint(\"Results with threshold=0.5:\")\nprint(f\"Accuracy:  {evaluation['accuracy']:.4f}\")\nprint(f\"Precision: {evaluation['precision']:.4f}\")\nprint(f\"Recall:    {evaluation['recall']:.4f} (Sensitivity)\")\nprint(f\"F1-Score:  {evaluation['f1_score']:.4f}\")\nprint(\"Confusion Matrix:\")\nprint(f\"  True Positives:  {evaluation['confusion_matrix']['tp']}\")\nprint(f\"  False Positives: {evaluation['confusion_matrix']['fp']}\")\nprint(f\"  True Negatives:  {evaluation['confusion_matrix']['tn']}\")\nprint(f\"  False Negatives: {evaluation['confusion_matrix']['fn']}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T07:36:19.698851Z","iopub.execute_input":"2025-04-11T07:36:19.699167Z","iopub.status.idle":"2025-04-11T07:36:21.494436Z","shell.execute_reply.started":"2025-04-11T07:36:19.699136Z","shell.execute_reply":"2025-04-11T07:36:21.493579Z"}},"outputs":[{"name":"stdout","text":"\n--- Evaluating Model on Test Set ---\nResults with threshold=0.5:\nAccuracy:  0.9992\nPrecision: 0.8400\nRecall:    0.6429 (Sensitivity)\nF1-Score:  0.7283\nConfusion Matrix:\n  True Positives:  63\n  False Positives: 12\n  True Negatives:  56534\n  False Negatives: 35\n","output_type":"stream"}],"execution_count":28},{"cell_type":"markdown","source":"## Threshold Tuning and AUC Calculation\nWe explore model performance further:\n- Test different decision thresholds (0.1 to 0.9) to balance precision and recall, as the default 0.5 may not be optimal for imbalanced data.\n- Calculate the Area Under the ROC Curve (AUC) using an approximation with the trapezoidal rule, a key metric for imbalanced datasets.\n- Print the results for each threshold and the AUC value.","metadata":{}},{"cell_type":"code","source":"# Try different thresholds to find better precision-recall balance\nprint(\"\\n--- Evaluating Different Thresholds ---\")\nthresholds = [0.1, 0.3, 0.5, 0.7, 0.9]\nfor threshold in thresholds:\n    eval_result = evaluate_model(test_rdd, current_weights, threshold)\n    print(f\"Threshold={threshold:.1f} | Precision: {eval_result['precision']:.4f} | Recall: {eval_result['recall']:.4f} | F1: {eval_result['f1_score']:.4f}\")\n\n# Calculate AUC\ndef calculate_auc_approximation(test_data, weights):\n    \"\"\"Calculate an approximation of the AUC using discrete thresholds\"\"\"\n    # Function to get prediction probabilities and actual labels\n    def get_prediction_score(record):\n        features, actual_label = record\n        prob = predict(features, weights)\n        return (prob, actual_label)\n    \n    # Get prediction scores and sort them\n    pred_scores = test_data.map(get_prediction_score).collect()\n    pred_scores.sort(key=lambda x: x[0], reverse=True)\n    \n    # Initialize counters\n    num_positive = sum(1 for _, label in pred_scores if label == 1.0)\n    num_negative = len(pred_scores) - num_positive\n    \n    if num_positive == 0 or num_negative == 0:\n        print(\"Warning: Only one class present in test set. AUC calculation not possible.\")\n        return 0.0\n    \n    # Initialize the area\n    auc = 0.0\n    tp = 0\n    fp = 0\n    prev_fp = 0\n    prev_tp = 0\n    \n    # Process each prediction\n    for prob, label in pred_scores:\n        if label == 1.0:\n            tp += 1\n        else:\n            fp += 1\n            \n        # Add trapezoid area under the curve\n        if fp > prev_fp:\n            auc += (tp + prev_tp) * (fp - prev_fp) / (2.0 * num_positive * num_negative)\n            prev_fp = fp\n            prev_tp = tp\n    \n    return auc\n\nprint(\"\\n--- AUC Approximation ---\")\nauc = calculate_auc_approximation(test_rdd, current_weights)\nprint(f\"Area Under ROC Curve (AUC): {auc:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T07:36:21.495377Z","iopub.execute_input":"2025-04-11T07:36:21.495600Z","iopub.status.idle":"2025-04-11T07:36:31.523044Z","shell.execute_reply.started":"2025-04-11T07:36:21.495580Z","shell.execute_reply":"2025-04-11T07:36:31.522197Z"}},"outputs":[{"name":"stdout","text":"\n--- Evaluating Different Thresholds ---\nThreshold=0.1 | Precision: 0.0017 | Recall: 1.0000 | F1: 0.0035\nThreshold=0.3 | Precision: 0.0017 | Recall: 1.0000 | F1: 0.0035\nThreshold=0.5 | Precision: 0.8400 | Recall: 0.6429 | F1: 0.7283\nThreshold=0.7 | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000\nThreshold=0.9 | Precision: 0.0000 | Recall: 0.0000 | F1: 0.0000\n\n--- AUC Approximation ---\nArea Under ROC Curve (AUC): 0.9617\n","output_type":"stream"}],"execution_count":29},{"cell_type":"markdown","source":"## Cleanup and Shutdown\nWe clean up resources to free memory and stop the Spark session:\n- Unpersist cached RDDs (`train_rdd`, `test_rdd`).\n- Unpersist broadcast variables.\n- Stop the Spark session to ensure proper shutdown.","metadata":{}},{"cell_type":"code","source":"# Clean up\n\ntrain_rdd.unpersist()\ntest_rdd.unpersist()\nbc_min_features.unpersist()\nbc_max_features.unpersist()\nbc_feature_ranges.unpersist()\nbc_class_weights.unpersist()\n\n# Stop Spark session\nprint(\"--- Stopping Spark Session ---\")\nspark.stop()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T07:36:31.523745Z","iopub.execute_input":"2025-04-11T07:36:31.524032Z","iopub.status.idle":"2025-04-11T07:36:32.471105Z","shell.execute_reply.started":"2025-04-11T07:36:31.524002Z","shell.execute_reply":"2025-04-11T07:36:32.470178Z"}},"outputs":[{"name":"stdout","text":"--- Stopping Spark Session ---\n","output_type":"stream"}],"execution_count":30}]}